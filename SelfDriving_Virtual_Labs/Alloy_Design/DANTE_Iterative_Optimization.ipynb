{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b15bdfb9",
   "metadata": {},
   "source": [
    "# DANTE迭代优化系统：科学计算反馈闭环\n",
    "\n",
    "本notebook展示了一个完整的迭代优化系统，其中：\n",
    "1. DANTE算法找到最优候选解\n",
    "2. 将候选解输入科学计算软件（模拟DFT/VASP计算）\n",
    "3. 根据科学计算结果更新训练数据\n",
    "4. 重新训练代理神经网络模型\n",
    "5. 继续DANTE优化过程\n",
    "\n",
    "这个闭环系统能够持续改进模型精度并发现更优的材料设计。\n",
    "\n",
    "## 系统架构\n",
    "\n",
    "```\n",
    "DANTE优化 → 候选解 → 科学计算验证 → 数据更新 → 模型重训练 → DANTE优化...\n",
    "    ↑                                                           ↓\n",
    "    ←←←←←←←←←←←←← 持续迭代优化 ←←←←←←←←←←←←←←←←←←←←←←←←←←←←\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf5b7d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-26 20:35:00.742337: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-26 20:35:00.748098: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-26 20:35:00.754900: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-26 20:35:00.756923: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-26 20:35:00.762295: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "导入库完成！\n",
      "TensorFlow版本: 2.17.0\n",
      "当前时间: 2025-05-26 20:35:01\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# 设置随机种子以确保可重现性\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 设置可视化样式\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "print(\"导入库完成！\")\n",
    "print(f\"TensorFlow版本: {tf.__version__}\")\n",
    "print(f\"当前时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99563cb",
   "metadata": {},
   "source": [
    "## 第一部分：加载初始数据和DANTE框架"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "832b4eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功导入DANTE模块！\n",
      "成功加载初始数据集，共 621 个样本\n"
     ]
    }
   ],
   "source": [
    "# 添加DANTE模块到路径\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../..\")))\n",
    "\n",
    "# 导入DANTE模块\n",
    "try:\n",
    "    from dante.neural_surrogate import SurrogateModel\n",
    "    from dante.deep_active_learning import DeepActiveLearning\n",
    "    from dante.obj_functions import ObjectiveFunction\n",
    "    from dante.tree_exploration import TreeExploration\n",
    "    from dante.utils import generate_initial_samples, Tracker\n",
    "    print(\"成功导入DANTE模块！\")\n",
    "except ImportError as e:\n",
    "    print(f\"导入DANTE模块失败: {e}\")\n",
    "    print(\"请确保DANTE已正确安装\")\n",
    "\n",
    "# 加载初始数据\n",
    "data_path = \"data.csv\"\n",
    "if os.path.exists(data_path):\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"成功加载初始数据集，共 {len(df)} 个样本\")\n",
    "else:\n",
    "    print(\"警告：数据文件不存在！\")\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4cbbf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始数据预处理完成：621 个样本，4 个特征\n",
      "成分范围检查：Co[8.50, 11.20], Mo[4.90, 5.50], Ti[0.80, 3.00], Fe[80.30, 85.80]\n"
     ]
    }
   ],
   "source": [
    "# 从之前的notebook中复制成分提取函数\n",
    "def extract_composition(sid):\n",
    "    \"\"\"从材料ID中提取元素成分\"\"\"\n",
    "    elements = ['Co', 'Mo', 'Ti']\n",
    "    values = []\n",
    "    \n",
    "    for element in elements:\n",
    "        if element in sid:\n",
    "            pos = sid.find(element) + len(element)\n",
    "            next_pos = len(sid)\n",
    "            for next_elem in elements:\n",
    "                if next_elem != element and sid.find(next_elem, pos) != -1:\n",
    "                    next_pos = min(next_pos, sid.find(next_elem, pos))\n",
    "            value = float(sid[pos:next_pos])\n",
    "            values.append(value)\n",
    "        else:\n",
    "            values.append(0.0)\n",
    "    \n",
    "    co, mo, ti = values\n",
    "    fe = 100.0 - co - mo - ti\n",
    "    return [co, mo, ti, fe]\n",
    "\n",
    "# 预处理初始数据\n",
    "if df is not None:\n",
    "    composition_values = df['sid'].apply(extract_composition)\n",
    "    X_initial = np.array(composition_values.tolist())\n",
    "    \n",
    "    # 提取并标准化目标值\n",
    "    elastic_values = df['elastic'].values\n",
    "    yield_values = df['yield'].values\n",
    "    \n",
    "    elastic_min, elastic_max = np.min(elastic_values), np.max(elastic_values)\n",
    "    yield_min, yield_max = np.min(yield_values), np.max(yield_values)\n",
    "    \n",
    "    elastic_norm = (elastic_values - elastic_min) / (elastic_max - elastic_min)\n",
    "    yield_norm = (yield_values - yield_min) / (yield_max - yield_min)\n",
    "    Y_initial = (elastic_norm + yield_norm) / 2\n",
    "    \n",
    "    print(f\"初始数据预处理完成：{X_initial.shape[0]} 个样本，{X_initial.shape[1]} 个特征\")\n",
    "    print(f\"成分范围检查：Co[{X_initial[:, 0].min():.2f}, {X_initial[:, 0].max():.2f}], \"\n",
    "          f\"Mo[{X_initial[:, 1].min():.2f}, {X_initial[:, 1].max():.2f}], \"\n",
    "          f\"Ti[{X_initial[:, 2].min():.2f}, {X_initial[:, 2].max():.2f}], \"\n",
    "          f\"Fe[{X_initial[:, 3].min():.2f}, {X_initial[:, 3].max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d49c8c",
   "metadata": {},
   "source": [
    "## 第二部分：科学计算模拟器\n",
    "\n",
    "在实际应用中，这里会调用真正的科学计算软件（如VASP、LAMMPS等）。为了演示，我们创建一个模拟器来代表昂贵的科学计算过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8e55c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "科学计算模拟器创建完成！\n",
      "[科学计算 #1] 开始计算成分: Co=8.50%, Mo=5.15%, Ti=2.60%, Fe=83.75%\n",
      "[科学计算 #1] 计算完成 (用时: 0.50s)\n",
      "  弹性模量: 1.42e+11 Pa\n",
      "  屈服强度: 1032205215.19 Pa\n",
      "  综合性能: 0.709443\n",
      "科学计算模拟器测试成功！\n",
      "[科学计算 #1] 计算完成 (用时: 0.50s)\n",
      "  弹性模量: 1.42e+11 Pa\n",
      "  屈服强度: 1032205215.19 Pa\n",
      "  综合性能: 0.709443\n",
      "科学计算模拟器测试成功！\n"
     ]
    }
   ],
   "source": [
    "class ScientificComputationSimulator:\n",
    "    \"\"\"\n",
    "    科学计算模拟器\n",
    "    模拟真实的DFT/MD计算过程，包含噪声和计算时间\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_data_X, base_data_Y, noise_level=0.05, computation_time=1.0):\n",
    "        \"\"\"\n",
    "        参数:\n",
    "        - base_data_X, base_data_Y: 基础数据用于插值\n",
    "        - noise_level: 噪声水平（模拟计算误差）\n",
    "        - computation_time: 模拟计算时间（秒）\n",
    "        \"\"\"\n",
    "        self.base_X = base_data_X\n",
    "        self.base_Y = base_data_Y\n",
    "        self.noise_level = noise_level\n",
    "        self.computation_time = computation_time\n",
    "        self.calculation_count = 0\n",
    "        self.calculation_history = []\n",
    "        \n",
    "    def validate_composition(self, composition):\n",
    "        \"\"\"验证成分的物理合理性\"\"\"\n",
    "        # 检查成分是否为正数\n",
    "        if np.any(composition < 0):\n",
    "            return False, \"成分不能为负数\"\n",
    "        \n",
    "        # 检查成分总和是否接近100%\n",
    "        total = np.sum(composition)\n",
    "        if not np.isclose(total, 100.0, rtol=0.05):\n",
    "            return False, f\"成分总和不等于100%: {total:.2f}%\"\n",
    "        \n",
    "        # 检查是否在合理范围内\n",
    "        co, mo, ti, fe = composition\n",
    "        if co > 50 or mo > 30 or ti > 20 or fe < 30:\n",
    "            return False, \"成分超出合理范围\"\n",
    "        \n",
    "        return True, \"成分验证通过\"\n",
    "    \n",
    "    def compute_properties(self, composition):\n",
    "        \"\"\"\n",
    "        模拟科学计算过程\n",
    "        返回：弹性模量、屈服强度、计算成功标志\n",
    "        \"\"\"\n",
    "        self.calculation_count += 1\n",
    "        start_time = time.time()\n",
    "        \n",
    "        print(f\"[科学计算 #{self.calculation_count}] 开始计算成分: \"\n",
    "              f\"Co={composition[0]:.2f}%, Mo={composition[1]:.2f}%, \"\n",
    "              f\"Ti={composition[2]:.2f}%, Fe={composition[3]:.2f}%\")\n",
    "        \n",
    "        # 验证成分\n",
    "        is_valid, message = self.validate_composition(composition)\n",
    "        if not is_valid:\n",
    "            print(f\"[科学计算 #{self.calculation_count}] 计算失败: {message}\")\n",
    "            return None, None, False\n",
    "        \n",
    "        # 模拟计算时间\n",
    "        time.sleep(self.computation_time)\n",
    "        \n",
    "        # 使用最近邻插值加噪声来模拟真实计算\n",
    "        distances = np.linalg.norm(self.base_X - composition, axis=1)\n",
    "        nearest_indices = np.argsort(distances)[:3]  # 使用最近的3个点\n",
    "        \n",
    "        # 加权平均（距离越近权重越大）\n",
    "        weights = 1.0 / (distances[nearest_indices] + 1e-6)\n",
    "        weights = weights / np.sum(weights)\n",
    "        \n",
    "        # 插值得到基础性能值\n",
    "        base_performance = np.sum(weights * self.base_Y[nearest_indices])\n",
    "        \n",
    "        # 添加噪声模拟计算误差\n",
    "        noise = np.random.normal(0, self.noise_level)\n",
    "        noisy_performance = base_performance + noise\n",
    "        \n",
    "        # 将综合性能转换回弹性模量和屈服强度\n",
    "        # 这里使用简化的反向映射\n",
    "        elastic_base = np.mean([elastic_values[i] for i in nearest_indices])\n",
    "        yield_base = np.mean([yield_values[i] for i in nearest_indices])\n",
    "        \n",
    "        # 添加相关性噪声\n",
    "        elastic_noise = np.random.normal(0, elastic_base * 0.05)\n",
    "        yield_noise = np.random.normal(0, yield_base * 0.05)\n",
    "        \n",
    "        computed_elastic = max(elastic_base + elastic_noise, elastic_base * 0.5)\n",
    "        computed_yield = max(yield_base + yield_noise, yield_base * 0.5)\n",
    "        \n",
    "        computation_time = time.time() - start_time\n",
    "        \n",
    "        # 记录计算历史\n",
    "        calculation_record = {\n",
    "            'id': self.calculation_count,\n",
    "            'composition': composition.copy(),\n",
    "            'elastic_modulus': computed_elastic,\n",
    "            'yield_strength': computed_yield,\n",
    "            'performance': noisy_performance,\n",
    "            'computation_time': computation_time,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        self.calculation_history.append(calculation_record)\n",
    "        \n",
    "        print(f\"[科学计算 #{self.calculation_count}] 计算完成 \"\n",
    "              f\"(用时: {computation_time:.2f}s)\")\n",
    "        print(f\"  弹性模量: {computed_elastic:.2e} Pa\")\n",
    "        print(f\"  屈服强度: {computed_yield:.2f} Pa\")\n",
    "        print(f\"  综合性能: {noisy_performance:.6f}\")\n",
    "        \n",
    "        return computed_elastic, computed_yield, True\n",
    "    \n",
    "    def get_calculation_summary(self):\n",
    "        \"\"\"获取计算总结\"\"\"\n",
    "        if not self.calculation_history:\n",
    "            return \"尚未进行任何计算\"\n",
    "        \n",
    "        total_time = sum(record['computation_time'] for record in self.calculation_history)\n",
    "        return f\"总计算次数: {self.calculation_count}, 总用时: {total_time:.2f}秒\"\n",
    "\n",
    "# 创建科学计算模拟器\n",
    "if 'X_initial' in locals() and 'Y_initial' in locals():\n",
    "    sci_computer = ScientificComputationSimulator(\n",
    "        X_initial, Y_initial, \n",
    "        noise_level=0.03,  # 3% 噪声水平\n",
    "        computation_time=0.5  # 0.5秒模拟计算时间\n",
    "    )\n",
    "    print(\"科学计算模拟器创建完成！\")\n",
    "    \n",
    "    # 测试科学计算\n",
    "    test_composition = X_initial[0]\n",
    "    test_elastic, test_yield, test_success = sci_computer.compute_properties(test_composition)\n",
    "    if test_success:\n",
    "        print(\"科学计算模拟器测试成功！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59cf37e",
   "metadata": {},
   "source": [
    "## 第三部分：增强型代理模型\n",
    "\n",
    "创建一个能够持续学习的代理模型，支持增量训练和模型更新。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fb69f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用初始数据训练代理模型...\n",
      "\n",
      "=== 开始训练代理模型 (版本 1) ===\n",
      "训练数据: 621 个样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1748263059.252230   19076 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1748263059.276121   19076 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1748263059.276212   19076 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1748263059.277877   19076 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1748263059.277956   19076 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1748263059.278004   19076 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1748263059.327952   19076 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1748263059.328047   19076 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1748263059.328100   19076 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-26 20:37:39.328146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22272 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1748263060.617331   19318 service.cc:146] XLA service 0x7468c8015c20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1748263060.617358   19318 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-05-26 20:37:40.638957: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-05-26 20:37:40.734533: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 7/16\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2799 - mae: 0.884392"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1748263061.577191   19318 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 1.1725 - mae: 0.8438 - val_loss: 0.2041 - val_mae: 0.3952\n",
      "Epoch 2/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 1.1725 - mae: 0.8438 - val_loss: 0.2041 - val_mae: 0.3952\n",
      "Epoch 2/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4811 - mae: 0.5347 - val_loss: 0.1699 - val_mae: 0.3525\n",
      "Epoch 3/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4811 - mae: 0.5347 - val_loss: 0.1699 - val_mae: 0.3525\n",
      "Epoch 3/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2394 - mae: 0.3804 - val_loss: 0.1401 - val_mae: 0.3117\n",
      "Epoch 4/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2394 - mae: 0.3804 - val_loss: 0.1401 - val_mae: 0.3117\n",
      "Epoch 4/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2125 - mae: 0.3521 - val_loss: 0.1071 - val_mae: 0.2655\n",
      "Epoch 5/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2125 - mae: 0.3521 - val_loss: 0.1071 - val_mae: 0.2655\n",
      "Epoch 5/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1796 - mae: 0.3214 - val_loss: 0.0771 - val_mae: 0.2193\n",
      "Epoch 6/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1796 - mae: 0.3214 - val_loss: 0.0771 - val_mae: 0.2193\n",
      "Epoch 6/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1546 - mae: 0.3012 - val_loss: 0.0658 - val_mae: 0.2000\n",
      "Epoch 7/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1546 - mae: 0.3012 - val_loss: 0.0658 - val_mae: 0.2000\n",
      "Epoch 7/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1617 - mae: 0.3167 - val_loss: 0.0601 - val_mae: 0.1930\n",
      "Epoch 8/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1617 - mae: 0.3167 - val_loss: 0.0601 - val_mae: 0.1930\n",
      "Epoch 8/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1227 - mae: 0.2731 - val_loss: 0.0524 - val_mae: 0.1830\n",
      "Epoch 9/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1227 - mae: 0.2731 - val_loss: 0.0524 - val_mae: 0.1830\n",
      "Epoch 9/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0999 - mae: 0.2353 - val_loss: 0.0538 - val_mae: 0.1853\n",
      "Epoch 10/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0999 - mae: 0.2353 - val_loss: 0.0538 - val_mae: 0.1853\n",
      "Epoch 10/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0938 - mae: 0.2387 - val_loss: 0.0528 - val_mae: 0.1837\n",
      "Epoch 11/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0938 - mae: 0.2387 - val_loss: 0.0528 - val_mae: 0.1837\n",
      "Epoch 11/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0792 - mae: 0.2197 - val_loss: 0.0437 - val_mae: 0.1704\n",
      "Epoch 12/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0792 - mae: 0.2197 - val_loss: 0.0437 - val_mae: 0.1704\n",
      "Epoch 12/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0739 - mae: 0.2078 - val_loss: 0.0470 - val_mae: 0.1780\n",
      "Epoch 13/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0739 - mae: 0.2078 - val_loss: 0.0470 - val_mae: 0.1780\n",
      "Epoch 13/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0747 - mae: 0.2148 - val_loss: 0.0511 - val_mae: 0.1872\n",
      "Epoch 14/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0747 - mae: 0.2148 - val_loss: 0.0511 - val_mae: 0.1872\n",
      "Epoch 14/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0756 - mae: 0.2114 - val_loss: 0.0533 - val_mae: 0.1913\n",
      "Epoch 15/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0756 - mae: 0.2114 - val_loss: 0.0533 - val_mae: 0.1913\n",
      "Epoch 15/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0688 - mae: 0.2006 - val_loss: 0.0433 - val_mae: 0.1731\n",
      "Epoch 16/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0688 - mae: 0.2006 - val_loss: 0.0433 - val_mae: 0.1731\n",
      "Epoch 16/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0623 - mae: 0.1972 - val_loss: 0.0405 - val_mae: 0.1645\n",
      "Epoch 17/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0623 - mae: 0.1972 - val_loss: 0.0405 - val_mae: 0.1645\n",
      "Epoch 17/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0534 - mae: 0.1803 - val_loss: 0.0455 - val_mae: 0.1742\n",
      "Epoch 18/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0534 - mae: 0.1803 - val_loss: 0.0455 - val_mae: 0.1742\n",
      "Epoch 18/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0616 - mae: 0.1940 - val_loss: 0.0393 - val_mae: 0.1582\n",
      "Epoch 19/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0616 - mae: 0.1940 - val_loss: 0.0393 - val_mae: 0.1582\n",
      "Epoch 19/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0604 - mae: 0.1867 - val_loss: 0.0283 - val_mae: 0.1346\n",
      "Epoch 20/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0604 - mae: 0.1867 - val_loss: 0.0283 - val_mae: 0.1346\n",
      "Epoch 20/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0579 - mae: 0.1882 - val_loss: 0.0326 - val_mae: 0.1436\n",
      "Epoch 21/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0579 - mae: 0.1882 - val_loss: 0.0326 - val_mae: 0.1436\n",
      "Epoch 21/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0457 - mae: 0.1646 - val_loss: 0.0367 - val_mae: 0.1514\n",
      "Epoch 22/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0457 - mae: 0.1646 - val_loss: 0.0367 - val_mae: 0.1514\n",
      "Epoch 22/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0410 - mae: 0.1567 - val_loss: 0.0335 - val_mae: 0.1450\n",
      "Epoch 23/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0410 - mae: 0.1567 - val_loss: 0.0335 - val_mae: 0.1450\n",
      "Epoch 23/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0444 - mae: 0.1577 - val_loss: 0.0322 - val_mae: 0.1428\n",
      "Epoch 24/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0444 - mae: 0.1577 - val_loss: 0.0322 - val_mae: 0.1428\n",
      "Epoch 24/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0558 - mae: 0.1783 - val_loss: 0.0293 - val_mae: 0.1358\n",
      "Epoch 25/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0558 - mae: 0.1783 - val_loss: 0.0293 - val_mae: 0.1358\n",
      "Epoch 25/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0440 - mae: 0.1575 - val_loss: 0.0244 - val_mae: 0.1248\n",
      "Epoch 26/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0440 - mae: 0.1575 - val_loss: 0.0244 - val_mae: 0.1248\n",
      "Epoch 26/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0374 - mae: 0.1498 - val_loss: 0.0257 - val_mae: 0.1301\n",
      "Epoch 27/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0374 - mae: 0.1498 - val_loss: 0.0257 - val_mae: 0.1301\n",
      "Epoch 27/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0335 - mae: 0.1397 - val_loss: 0.0214 - val_mae: 0.1164\n",
      "Epoch 28/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0335 - mae: 0.1397 - val_loss: 0.0214 - val_mae: 0.1164\n",
      "Epoch 28/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0267 - mae: 0.1275 - val_loss: 0.0201 - val_mae: 0.1148\n",
      "Epoch 29/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0267 - mae: 0.1275 - val_loss: 0.0201 - val_mae: 0.1148\n",
      "Epoch 29/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0376 - mae: 0.1450 - val_loss: 0.0202 - val_mae: 0.1162\n",
      "Epoch 30/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0376 - mae: 0.1450 - val_loss: 0.0202 - val_mae: 0.1162\n",
      "Epoch 30/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0281 - mae: 0.1289 - val_loss: 0.0222 - val_mae: 0.1173\n",
      "Epoch 31/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0281 - mae: 0.1289 - val_loss: 0.0222 - val_mae: 0.1173\n",
      "Epoch 31/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0356 - mae: 0.1443 - val_loss: 0.0231 - val_mae: 0.1258\n",
      "Epoch 32/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0356 - mae: 0.1443 - val_loss: 0.0231 - val_mae: 0.1258\n",
      "Epoch 32/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0263 - mae: 0.1290 - val_loss: 0.0231 - val_mae: 0.1244\n",
      "Epoch 33/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0263 - mae: 0.1290 - val_loss: 0.0231 - val_mae: 0.1244\n",
      "Epoch 33/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0306 - mae: 0.1363 - val_loss: 0.0154 - val_mae: 0.0980\n",
      "Epoch 34/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0306 - mae: 0.1363 - val_loss: 0.0154 - val_mae: 0.0980\n",
      "Epoch 34/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0311 - mae: 0.1374 - val_loss: 0.0134 - val_mae: 0.0913\n",
      "Epoch 35/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0311 - mae: 0.1374 - val_loss: 0.0134 - val_mae: 0.0913\n",
      "Epoch 35/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0311 - mae: 0.1361 - val_loss: 0.0266 - val_mae: 0.1344\n",
      "Epoch 36/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0311 - mae: 0.1361 - val_loss: 0.0266 - val_mae: 0.1344\n",
      "Epoch 36/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0327 - mae: 0.1344 - val_loss: 0.0162 - val_mae: 0.1004\n",
      "Epoch 37/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0327 - mae: 0.1344 - val_loss: 0.0162 - val_mae: 0.1004\n",
      "Epoch 37/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0285 - mae: 0.1318 - val_loss: 0.0195 - val_mae: 0.1096\n",
      "Epoch 38/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0285 - mae: 0.1318 - val_loss: 0.0195 - val_mae: 0.1096\n",
      "Epoch 38/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0233 - mae: 0.1186 - val_loss: 0.0123 - val_mae: 0.0862\n",
      "Epoch 39/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0233 - mae: 0.1186 - val_loss: 0.0123 - val_mae: 0.0862\n",
      "Epoch 39/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0246 - mae: 0.1191 - val_loss: 0.0141 - val_mae: 0.0944\n",
      "Epoch 40/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0246 - mae: 0.1191 - val_loss: 0.0141 - val_mae: 0.0944\n",
      "Epoch 40/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0219 - mae: 0.1124 - val_loss: 0.0140 - val_mae: 0.0924\n",
      "Epoch 41/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0219 - mae: 0.1124 - val_loss: 0.0140 - val_mae: 0.0924\n",
      "Epoch 41/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0214 - mae: 0.1140 - val_loss: 0.0165 - val_mae: 0.1023\n",
      "Epoch 42/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0214 - mae: 0.1140 - val_loss: 0.0165 - val_mae: 0.1023\n",
      "Epoch 42/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0211 - mae: 0.1102 - val_loss: 0.0175 - val_mae: 0.1053\n",
      "Epoch 43/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0211 - mae: 0.1102 - val_loss: 0.0175 - val_mae: 0.1053\n",
      "Epoch 43/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0214 - mae: 0.1166 - val_loss: 0.0221 - val_mae: 0.1163\n",
      "Epoch 44/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0214 - mae: 0.1166 - val_loss: 0.0221 - val_mae: 0.1163\n",
      "Epoch 44/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0221 - mae: 0.1187 - val_loss: 0.0268 - val_mae: 0.1326\n",
      "Epoch 45/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0221 - mae: 0.1187 - val_loss: 0.0268 - val_mae: 0.1326\n",
      "Epoch 45/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0242 - mae: 0.1166 - val_loss: 0.0123 - val_mae: 0.0896\n",
      "Epoch 46/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0242 - mae: 0.1166 - val_loss: 0.0123 - val_mae: 0.0896\n",
      "Epoch 46/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0211 - mae: 0.1105 - val_loss: 0.0134 - val_mae: 0.0935\n",
      "Epoch 47/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0211 - mae: 0.1105 - val_loss: 0.0134 - val_mae: 0.0935\n",
      "Epoch 47/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0200 - mae: 0.1128 - val_loss: 0.0130 - val_mae: 0.0885\n",
      "Epoch 48/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0200 - mae: 0.1128 - val_loss: 0.0130 - val_mae: 0.0885\n",
      "Epoch 48/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0230 - mae: 0.1167 - val_loss: 0.0229 - val_mae: 0.1179\n",
      "Epoch 49/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0230 - mae: 0.1167 - val_loss: 0.0229 - val_mae: 0.1179\n",
      "Epoch 49/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0184 - mae: 0.1085 - val_loss: 0.0170 - val_mae: 0.1001\n",
      "Epoch 50/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0184 - mae: 0.1085 - val_loss: 0.0170 - val_mae: 0.1001\n",
      "Epoch 50/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0216 - mae: 0.1157 - val_loss: 0.0282 - val_mae: 0.1292\n",
      "Epoch 51/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0216 - mae: 0.1157 - val_loss: 0.0282 - val_mae: 0.1292\n",
      "Epoch 51/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0184 - mae: 0.1047 - val_loss: 0.0144 - val_mae: 0.0960\n",
      "Epoch 52/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0184 - mae: 0.1047 - val_loss: 0.0144 - val_mae: 0.0960\n",
      "Epoch 52/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0185 - mae: 0.1108 - val_loss: 0.0131 - val_mae: 0.0891\n",
      "Epoch 53/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0185 - mae: 0.1108 - val_loss: 0.0131 - val_mae: 0.0891\n",
      "Epoch 53/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0164 - mae: 0.1007 - val_loss: 0.0131 - val_mae: 0.0917\n",
      "Epoch 54/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0164 - mae: 0.1007 - val_loss: 0.0131 - val_mae: 0.0917\n",
      "Epoch 54/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0164 - mae: 0.1020 - val_loss: 0.0141 - val_mae: 0.0924\n",
      "Epoch 55/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0164 - mae: 0.1020 - val_loss: 0.0141 - val_mae: 0.0924\n",
      "Epoch 55/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0182 - mae: 0.1054 - val_loss: 0.0136 - val_mae: 0.0943\n",
      "Epoch 56/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0182 - mae: 0.1054 - val_loss: 0.0136 - val_mae: 0.0943\n",
      "Epoch 56/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0186 - mae: 0.1060 - val_loss: 0.0118 - val_mae: 0.0861\n",
      "Epoch 57/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0186 - mae: 0.1060 - val_loss: 0.0118 - val_mae: 0.0861\n",
      "Epoch 57/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0159 - mae: 0.0996 - val_loss: 0.0102 - val_mae: 0.0801\n",
      "Epoch 58/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0159 - mae: 0.0996 - val_loss: 0.0102 - val_mae: 0.0801\n",
      "Epoch 58/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0173 - mae: 0.1032 - val_loss: 0.0116 - val_mae: 0.0856\n",
      "Epoch 59/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0173 - mae: 0.1032 - val_loss: 0.0116 - val_mae: 0.0856\n",
      "Epoch 59/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0178 - mae: 0.1041 - val_loss: 0.0121 - val_mae: 0.0875\n",
      "Epoch 60/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0178 - mae: 0.1041 - val_loss: 0.0121 - val_mae: 0.0875\n",
      "Epoch 60/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0140 - mae: 0.0937 - val_loss: 0.0119 - val_mae: 0.0883\n",
      "Epoch 61/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0140 - mae: 0.0937 - val_loss: 0.0119 - val_mae: 0.0883\n",
      "Epoch 61/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0173 - mae: 0.1025 - val_loss: 0.0116 - val_mae: 0.0852\n",
      "Epoch 62/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0173 - mae: 0.1025 - val_loss: 0.0116 - val_mae: 0.0852\n",
      "Epoch 62/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0128 - mae: 0.0896 - val_loss: 0.0097 - val_mae: 0.0787\n",
      "Epoch 63/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0128 - mae: 0.0896 - val_loss: 0.0097 - val_mae: 0.0787\n",
      "Epoch 63/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0160 - mae: 0.1007 - val_loss: 0.0090 - val_mae: 0.0759\n",
      "Epoch 64/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0160 - mae: 0.1007 - val_loss: 0.0090 - val_mae: 0.0759\n",
      "Epoch 64/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0141 - mae: 0.0920 - val_loss: 0.0089 - val_mae: 0.0749\n",
      "Epoch 65/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0141 - mae: 0.0920 - val_loss: 0.0089 - val_mae: 0.0749\n",
      "Epoch 65/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0128 - mae: 0.0871 - val_loss: 0.0088 - val_mae: 0.0741\n",
      "Epoch 66/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0128 - mae: 0.0871 - val_loss: 0.0088 - val_mae: 0.0741\n",
      "Epoch 66/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121 - mae: 0.0861 - val_loss: 0.0123 - val_mae: 0.0883\n",
      "Epoch 67/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121 - mae: 0.0861 - val_loss: 0.0123 - val_mae: 0.0883\n",
      "Epoch 67/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0159 - mae: 0.0911 - val_loss: 0.0124 - val_mae: 0.0877\n",
      "Epoch 68/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0159 - mae: 0.0911 - val_loss: 0.0124 - val_mae: 0.0877\n",
      "Epoch 68/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0159 - mae: 0.0958 - val_loss: 0.0084 - val_mae: 0.0738\n",
      "Epoch 69/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0159 - mae: 0.0958 - val_loss: 0.0084 - val_mae: 0.0738\n",
      "Epoch 69/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0154 - mae: 0.0911 - val_loss: 0.0094 - val_mae: 0.0767\n",
      "Epoch 70/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0154 - mae: 0.0911 - val_loss: 0.0094 - val_mae: 0.0767\n",
      "Epoch 70/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0142 - mae: 0.0915 - val_loss: 0.0088 - val_mae: 0.0737\n",
      "Epoch 71/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0142 - mae: 0.0915 - val_loss: 0.0088 - val_mae: 0.0737\n",
      "Epoch 71/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0133 - mae: 0.0891 - val_loss: 0.0092 - val_mae: 0.0744\n",
      "Epoch 72/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0133 - mae: 0.0891 - val_loss: 0.0092 - val_mae: 0.0744\n",
      "Epoch 72/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0133 - mae: 0.0910 - val_loss: 0.0100 - val_mae: 0.0791\n",
      "Epoch 73/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0133 - mae: 0.0910 - val_loss: 0.0100 - val_mae: 0.0791\n",
      "Epoch 73/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0131 - mae: 0.0898 - val_loss: 0.0104 - val_mae: 0.0807\n",
      "Epoch 74/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0131 - mae: 0.0898 - val_loss: 0.0104 - val_mae: 0.0807\n",
      "Epoch 74/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0135 - mae: 0.0909 - val_loss: 0.0086 - val_mae: 0.0734\n",
      "Epoch 75/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0135 - mae: 0.0909 - val_loss: 0.0086 - val_mae: 0.0734\n",
      "Epoch 75/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0142 - mae: 0.0917 - val_loss: 0.0092 - val_mae: 0.0768\n",
      "Epoch 76/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0142 - mae: 0.0917 - val_loss: 0.0092 - val_mae: 0.0768\n",
      "Epoch 76/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0145 - mae: 0.0916 - val_loss: 0.0096 - val_mae: 0.0788\n",
      "Epoch 77/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0145 - mae: 0.0916 - val_loss: 0.0096 - val_mae: 0.0788\n",
      "Epoch 77/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0139 - mae: 0.0930 - val_loss: 0.0109 - val_mae: 0.0857\n",
      "Epoch 78/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0139 - mae: 0.0930 - val_loss: 0.0109 - val_mae: 0.0857\n",
      "Epoch 78/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0127 - mae: 0.0877 - val_loss: 0.0095 - val_mae: 0.0786\n",
      "Epoch 79/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0127 - mae: 0.0877 - val_loss: 0.0095 - val_mae: 0.0786\n",
      "Epoch 79/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0115 - mae: 0.0865 - val_loss: 0.0105 - val_mae: 0.0825\n",
      "Epoch 80/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0115 - mae: 0.0865 - val_loss: 0.0105 - val_mae: 0.0825\n",
      "Epoch 80/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0125 - mae: 0.0870 - val_loss: 0.0095 - val_mae: 0.0774\n",
      "Epoch 81/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0125 - mae: 0.0870 - val_loss: 0.0095 - val_mae: 0.0774\n",
      "Epoch 81/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0105 - mae: 0.0807 - val_loss: 0.0102 - val_mae: 0.0807\n",
      "Epoch 82/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0105 - mae: 0.0807 - val_loss: 0.0102 - val_mae: 0.0807\n",
      "Epoch 82/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0133 - mae: 0.0899 - val_loss: 0.0095 - val_mae: 0.0774\n",
      "Epoch 83/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0133 - mae: 0.0899 - val_loss: 0.0095 - val_mae: 0.0774\n",
      "Epoch 83/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0133 - mae: 0.0874 - val_loss: 0.0109 - val_mae: 0.0837\n",
      "Epoch 84/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0133 - mae: 0.0874 - val_loss: 0.0109 - val_mae: 0.0837\n",
      "Epoch 84/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0117 - mae: 0.0858 - val_loss: 0.0088 - val_mae: 0.0748\n",
      "Epoch 85/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0117 - mae: 0.0858 - val_loss: 0.0088 - val_mae: 0.0748\n",
      "Epoch 85/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0155 - mae: 0.0948 - val_loss: 0.0115 - val_mae: 0.0861\n",
      "Epoch 86/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0155 - mae: 0.0948 - val_loss: 0.0115 - val_mae: 0.0861\n",
      "Epoch 86/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0113 - mae: 0.0829 - val_loss: 0.0105 - val_mae: 0.0827\n",
      "Epoch 87/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0113 - mae: 0.0829 - val_loss: 0.0105 - val_mae: 0.0827\n",
      "Epoch 87/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0111 - mae: 0.0831 - val_loss: 0.0075 - val_mae: 0.0675\n",
      "Epoch 88/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0111 - mae: 0.0831 - val_loss: 0.0075 - val_mae: 0.0675\n",
      "Epoch 88/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0102 - mae: 0.0801 - val_loss: 0.0088 - val_mae: 0.0743\n",
      "Epoch 89/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0102 - mae: 0.0801 - val_loss: 0.0088 - val_mae: 0.0743\n",
      "Epoch 89/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0120 - mae: 0.0847 - val_loss: 0.0088 - val_mae: 0.0738\n",
      "Epoch 90/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0120 - mae: 0.0847 - val_loss: 0.0088 - val_mae: 0.0738\n",
      "Epoch 90/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0118 - mae: 0.0822 - val_loss: 0.0075 - val_mae: 0.0679\n",
      "Epoch 91/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0118 - mae: 0.0822 - val_loss: 0.0075 - val_mae: 0.0679\n",
      "Epoch 91/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0091 - mae: 0.0752 - val_loss: 0.0077 - val_mae: 0.0682\n",
      "Epoch 92/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0091 - mae: 0.0752 - val_loss: 0.0077 - val_mae: 0.0682\n",
      "Epoch 92/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0089 - mae: 0.0730 - val_loss: 0.0072 - val_mae: 0.0651\n",
      "Epoch 93/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0089 - mae: 0.0730 - val_loss: 0.0072 - val_mae: 0.0651\n",
      "Epoch 93/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0091 - mae: 0.0750 - val_loss: 0.0080 - val_mae: 0.0690\n",
      "Epoch 94/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0091 - mae: 0.0750 - val_loss: 0.0080 - val_mae: 0.0690\n",
      "Epoch 94/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0095 - mae: 0.0783 - val_loss: 0.0079 - val_mae: 0.0718\n",
      "Epoch 95/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0095 - mae: 0.0783 - val_loss: 0.0079 - val_mae: 0.0718\n",
      "Epoch 95/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0110 - mae: 0.0813 - val_loss: 0.0083 - val_mae: 0.0739\n",
      "Epoch 96/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0110 - mae: 0.0813 - val_loss: 0.0083 - val_mae: 0.0739\n",
      "Epoch 96/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0090 - mae: 0.0740 - val_loss: 0.0094 - val_mae: 0.0800\n",
      "Epoch 97/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0090 - mae: 0.0740 - val_loss: 0.0094 - val_mae: 0.0800\n",
      "Epoch 97/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0108 - mae: 0.0810 - val_loss: 0.0064 - val_mae: 0.0626\n",
      "Epoch 98/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0108 - mae: 0.0810 - val_loss: 0.0064 - val_mae: 0.0626\n",
      "Epoch 98/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0105 - mae: 0.0794 - val_loss: 0.0060 - val_mae: 0.0611\n",
      "Epoch 99/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0105 - mae: 0.0794 - val_loss: 0.0060 - val_mae: 0.0611\n",
      "Epoch 99/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0094 - mae: 0.0757 - val_loss: 0.0069 - val_mae: 0.0653\n",
      "Epoch 100/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0094 - mae: 0.0757 - val_loss: 0.0069 - val_mae: 0.0653\n",
      "Epoch 100/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - mae: 0.0765 - val_loss: 0.0076 - val_mae: 0.0697\n",
      "Epoch 101/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - mae: 0.0765 - val_loss: 0.0076 - val_mae: 0.0697\n",
      "Epoch 101/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0093 - mae: 0.0773 - val_loss: 0.0095 - val_mae: 0.0809\n",
      "Epoch 102/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0093 - mae: 0.0773 - val_loss: 0.0095 - val_mae: 0.0809\n",
      "Epoch 102/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0087 - mae: 0.0731 - val_loss: 0.0069 - val_mae: 0.0661\n",
      "Epoch 103/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0087 - mae: 0.0731 - val_loss: 0.0069 - val_mae: 0.0661\n",
      "Epoch 103/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0100 - mae: 0.0788 - val_loss: 0.0074 - val_mae: 0.0672\n",
      "Epoch 104/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0100 - mae: 0.0788 - val_loss: 0.0074 - val_mae: 0.0672\n",
      "Epoch 104/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0092 - mae: 0.0762 - val_loss: 0.0070 - val_mae: 0.0665\n",
      "Epoch 105/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0092 - mae: 0.0762 - val_loss: 0.0070 - val_mae: 0.0665\n",
      "Epoch 105/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0113 - mae: 0.0842 - val_loss: 0.0071 - val_mae: 0.0679\n",
      "Epoch 106/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0113 - mae: 0.0842 - val_loss: 0.0071 - val_mae: 0.0679\n",
      "Epoch 106/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0094 - mae: 0.0760 - val_loss: 0.0067 - val_mae: 0.0653\n",
      "Epoch 107/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0094 - mae: 0.0760 - val_loss: 0.0067 - val_mae: 0.0653\n",
      "Epoch 107/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0093 - mae: 0.0763 - val_loss: 0.0085 - val_mae: 0.0750\n",
      "Epoch 108/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0093 - mae: 0.0763 - val_loss: 0.0085 - val_mae: 0.0750\n",
      "Epoch 108/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - mae: 0.0815 - val_loss: 0.0064 - val_mae: 0.0628\n",
      "Epoch 109/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - mae: 0.0815 - val_loss: 0.0064 - val_mae: 0.0628\n",
      "Epoch 109/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0107 - mae: 0.0824 - val_loss: 0.0061 - val_mae: 0.0610\n",
      "Epoch 110/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0107 - mae: 0.0824 - val_loss: 0.0061 - val_mae: 0.0610\n",
      "Epoch 110/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0095 - mae: 0.0768 - val_loss: 0.0068 - val_mae: 0.0646\n",
      "Epoch 111/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0095 - mae: 0.0768 - val_loss: 0.0068 - val_mae: 0.0646\n",
      "Epoch 111/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - mae: 0.0782 - val_loss: 0.0060 - val_mae: 0.0602\n",
      "Epoch 112/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - mae: 0.0782 - val_loss: 0.0060 - val_mae: 0.0602\n",
      "Epoch 112/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0091 - mae: 0.0732 - val_loss: 0.0086 - val_mae: 0.0747\n",
      "Epoch 113/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0091 - mae: 0.0732 - val_loss: 0.0086 - val_mae: 0.0747\n",
      "Epoch 113/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0099 - mae: 0.0759 - val_loss: 0.0086 - val_mae: 0.0746\n",
      "Epoch 114/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0099 - mae: 0.0759 - val_loss: 0.0086 - val_mae: 0.0746\n",
      "Epoch 114/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - mae: 0.0752 - val_loss: 0.0068 - val_mae: 0.0633\n",
      "Epoch 115/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - mae: 0.0752 - val_loss: 0.0068 - val_mae: 0.0633\n",
      "Epoch 115/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - mae: 0.0778 - val_loss: 0.0076 - val_mae: 0.0686\n",
      "Epoch 116/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - mae: 0.0778 - val_loss: 0.0076 - val_mae: 0.0686\n",
      "Epoch 116/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - mae: 0.0737 - val_loss: 0.0059 - val_mae: 0.0597\n",
      "Epoch 117/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - mae: 0.0737 - val_loss: 0.0059 - val_mae: 0.0597\n",
      "Epoch 117/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0093 - mae: 0.0765 - val_loss: 0.0060 - val_mae: 0.0608\n",
      "Epoch 118/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0093 - mae: 0.0765 - val_loss: 0.0060 - val_mae: 0.0608\n",
      "Epoch 118/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - mae: 0.0695 - val_loss: 0.0065 - val_mae: 0.0630\n",
      "Epoch 119/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - mae: 0.0695 - val_loss: 0.0065 - val_mae: 0.0630\n",
      "Epoch 119/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0097 - mae: 0.0789 - val_loss: 0.0060 - val_mae: 0.0599\n",
      "Epoch 120/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0097 - mae: 0.0789 - val_loss: 0.0060 - val_mae: 0.0599\n",
      "Epoch 120/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - mae: 0.0775 - val_loss: 0.0066 - val_mae: 0.0633\n",
      "Epoch 121/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - mae: 0.0775 - val_loss: 0.0066 - val_mae: 0.0633\n",
      "Epoch 121/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0085 - mae: 0.0720 - val_loss: 0.0058 - val_mae: 0.0595\n",
      "Epoch 122/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0085 - mae: 0.0720 - val_loss: 0.0058 - val_mae: 0.0595\n",
      "Epoch 122/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - mae: 0.0700 - val_loss: 0.0084 - val_mae: 0.0729\n",
      "Epoch 123/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - mae: 0.0700 - val_loss: 0.0084 - val_mae: 0.0729\n",
      "Epoch 123/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0085 - mae: 0.0749 - val_loss: 0.0074 - val_mae: 0.0672\n",
      "Epoch 124/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0085 - mae: 0.0749 - val_loss: 0.0074 - val_mae: 0.0672\n",
      "Epoch 124/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - mae: 0.0722 - val_loss: 0.0073 - val_mae: 0.0673\n",
      "Epoch 125/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - mae: 0.0722 - val_loss: 0.0073 - val_mae: 0.0673\n",
      "Epoch 125/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - mae: 0.0727 - val_loss: 0.0074 - val_mae: 0.0677\n",
      "Epoch 126/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - mae: 0.0727 - val_loss: 0.0074 - val_mae: 0.0677\n",
      "Epoch 126/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - mae: 0.0688 - val_loss: 0.0075 - val_mae: 0.0680\n",
      "Epoch 127/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - mae: 0.0688 - val_loss: 0.0075 - val_mae: 0.0680\n",
      "Epoch 127/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - mae: 0.0753 - val_loss: 0.0078 - val_mae: 0.0681\n",
      "Epoch 128/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - mae: 0.0753 - val_loss: 0.0078 - val_mae: 0.0681\n",
      "Epoch 128/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0083 - mae: 0.0711 - val_loss: 0.0079 - val_mae: 0.0682\n",
      "Epoch 129/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0083 - mae: 0.0711 - val_loss: 0.0079 - val_mae: 0.0682\n",
      "Epoch 129/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - mae: 0.0719 - val_loss: 0.0067 - val_mae: 0.0633\n",
      "Epoch 130/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - mae: 0.0719 - val_loss: 0.0067 - val_mae: 0.0633\n",
      "Epoch 130/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0086 - mae: 0.0706 - val_loss: 0.0074 - val_mae: 0.0663\n",
      "Epoch 131/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0086 - mae: 0.0706 - val_loss: 0.0074 - val_mae: 0.0663\n",
      "Epoch 131/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - mae: 0.0703 - val_loss: 0.0093 - val_mae: 0.0733\n",
      "Epoch 132/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - mae: 0.0703 - val_loss: 0.0093 - val_mae: 0.0733\n",
      "Epoch 132/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - mae: 0.0705 - val_loss: 0.0079 - val_mae: 0.0687\n",
      "Epoch 133/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - mae: 0.0705 - val_loss: 0.0079 - val_mae: 0.0687\n",
      "Epoch 133/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0071 - mae: 0.0667 - val_loss: 0.0073 - val_mae: 0.0660\n",
      "Epoch 134/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0071 - mae: 0.0667 - val_loss: 0.0073 - val_mae: 0.0660\n",
      "Epoch 134/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0072 - mae: 0.0668 - val_loss: 0.0074 - val_mae: 0.0673\n",
      "Epoch 135/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0072 - mae: 0.0668 - val_loss: 0.0074 - val_mae: 0.0673\n",
      "Epoch 135/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - mae: 0.0733 - val_loss: 0.0075 - val_mae: 0.0659\n",
      "Epoch 136/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - mae: 0.0733 - val_loss: 0.0075 - val_mae: 0.0659\n",
      "Epoch 136/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - mae: 0.0669 - val_loss: 0.0083 - val_mae: 0.0702\n",
      "Epoch 137/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - mae: 0.0669 - val_loss: 0.0083 - val_mae: 0.0702\n",
      "Epoch 137/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - mae: 0.0745 - val_loss: 0.0074 - val_mae: 0.0669\n",
      "Epoch 138/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - mae: 0.0745 - val_loss: 0.0074 - val_mae: 0.0669\n",
      "Epoch 138/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - mae: 0.0743 - val_loss: 0.0075 - val_mae: 0.0671\n",
      "Epoch 139/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - mae: 0.0743 - val_loss: 0.0075 - val_mae: 0.0671\n",
      "Epoch 139/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - mae: 0.0691 - val_loss: 0.0063 - val_mae: 0.0604\n",
      "Epoch 140/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - mae: 0.0691 - val_loss: 0.0063 - val_mae: 0.0604\n",
      "Epoch 140/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - mae: 0.0712 - val_loss: 0.0065 - val_mae: 0.0616\n",
      "Epoch 141/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - mae: 0.0712 - val_loss: 0.0065 - val_mae: 0.0616\n",
      "Epoch 141/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0085 - mae: 0.0725 - val_loss: 0.0062 - val_mae: 0.0598\n",
      "Epoch 141: early stopping\n",
      "Restoring model weights from the end of the best epoch: 121.\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0085 - mae: 0.0725 - val_loss: 0.0062 - val_mae: 0.0598\n",
      "Epoch 141: early stopping\n",
      "Restoring model weights from the end of the best epoch: 121.\n",
      "模型训练完成！最终损失: 0.008421, 验证损失: 0.006151\n",
      "模型训练完成！最终损失: 0.008421, 验证损失: 0.006151\n",
      "模型性能评估 (版本 1):\n",
      "  MSE: 0.004476\n",
      "  RMSE: 0.066900\n",
      "  R²: 0.918368\n",
      "模型性能评估 (版本 1):\n",
      "  MSE: 0.004476\n",
      "  RMSE: 0.066900\n",
      "  R²: 0.918368\n"
     ]
    }
   ],
   "source": [
    "class AdaptiveSurrogateModel:\n",
    "    \"\"\"\n",
    "    自适应代理模型\n",
    "    支持增量学习和模型性能跟踪\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dims=4, initial_lr=0.001):\n",
    "        self.input_dims = input_dims\n",
    "        self.initial_lr = initial_lr\n",
    "        self.model = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.is_fitted = False\n",
    "        self.training_history = []\n",
    "        self.model_version = 0\n",
    "        \n",
    "    def create_model(self, learning_rate=None):\n",
    "        \"\"\"创建神经网络模型\"\"\"\n",
    "        if learning_rate is None:\n",
    "            learning_rate = self.initial_lr\n",
    "            \n",
    "        model = keras.Sequential([\n",
    "            layers.Input(shape=(self.input_dims,)),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.3),\n",
    "            \n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.2),\n",
    "            \n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.1),\n",
    "            \n",
    "            layers.Dense(16, activation='relu'),\n",
    "            layers.Dense(1, activation='linear')\n",
    "        ])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, X, y, epochs=100, validation_split=0.2, verbose=1):\n",
    "        \"\"\"训练模型\"\"\"\n",
    "        print(f\"\\n=== 开始训练代理模型 (版本 {self.model_version + 1}) ===\")\n",
    "        print(f\"训练数据: {X.shape[0]} 个样本\")\n",
    "        \n",
    "        # 标准化特征\n",
    "        if not self.is_fitted:\n",
    "            X_scaled = self.scaler.fit_transform(X)\n",
    "            self.is_fitted = True\n",
    "        else:\n",
    "            # 增量更新标准化器\n",
    "            self.scaler.partial_fit(X)\n",
    "            X_scaled = self.scaler.transform(X)\n",
    "        \n",
    "        # 创建新模型或使用现有模型\n",
    "        if self.model is None:\n",
    "            self.model = self.create_model()\n",
    "        \n",
    "        # 设置回调\n",
    "        early_stop = EarlyStopping(\n",
    "            monitor='val_loss', \n",
    "            patience=20, \n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # 训练模型\n",
    "        history = self.model.fit(\n",
    "            X_scaled, y,\n",
    "            epochs=epochs,\n",
    "            validation_split=validation_split,\n",
    "            callbacks=[early_stop],\n",
    "            verbose=verbose\n",
    "        )\n",
    "        \n",
    "        # 记录训练历史\n",
    "        training_record = {\n",
    "            'version': self.model_version + 1,\n",
    "            'data_size': X.shape[0],\n",
    "            'final_loss': history.history['loss'][-1],\n",
    "            'final_val_loss': history.history['val_loss'][-1],\n",
    "            'epochs_trained': len(history.history['loss']),\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        self.training_history.append(training_record)\n",
    "        self.model_version += 1\n",
    "        \n",
    "        print(f\"模型训练完成！最终损失: {training_record['final_loss']:.6f}, \"\n",
    "              f\"验证损失: {training_record['final_val_loss']:.6f}\")\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"预测\"\"\"\n",
    "        if self.model is None or not self.is_fitted:\n",
    "            raise ValueError(\"模型尚未训练\")\n",
    "        \n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return self.model.predict(X_scaled, verbose=0)\n",
    "    \n",
    "    def evaluate_performance(self, X_test, y_test):\n",
    "        \"\"\"评估模型性能\"\"\"\n",
    "        if self.model is None:\n",
    "            return None\n",
    "            \n",
    "        y_pred = self.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        performance = {\n",
    "            'mse': mse,\n",
    "            'rmse': np.sqrt(mse),\n",
    "            'r2': r2,\n",
    "            'model_version': self.model_version\n",
    "        }\n",
    "        \n",
    "        print(f\"模型性能评估 (版本 {self.model_version}):\")\n",
    "        print(f\"  MSE: {mse:.6f}\")\n",
    "        print(f\"  RMSE: {np.sqrt(mse):.6f}\")\n",
    "        print(f\"  R²: {r2:.6f}\")\n",
    "        \n",
    "        return performance\n",
    "    \n",
    "    def save_model(self, filepath):\n",
    "        \"\"\"保存模型\"\"\"\n",
    "        if self.model is not None:\n",
    "            self.model.save(f\"{filepath}_v{self.model_version}.keras\")\n",
    "            \n",
    "    def get_training_summary(self):\n",
    "        \"\"\"获取训练总结\"\"\"\n",
    "        if not self.training_history:\n",
    "            return \"模型尚未训练\"\n",
    "        \n",
    "        summary = f\"模型训练历史 (当前版本: {self.model_version}):\\n\"\n",
    "        for record in self.training_history:\n",
    "            summary += f\"  版本 {record['version']}: {record['data_size']} 样本, \"\n",
    "            summary += f\"损失 {record['final_loss']:.6f}, 训练 {record['epochs_trained']} 轮\\n\"\n",
    "        \n",
    "        return summary\n",
    "\n",
    "# 创建自适应代理模型\n",
    "adaptive_model = AdaptiveSurrogateModel(input_dims=4)\n",
    "\n",
    "# 使用初始数据训练模型\n",
    "if 'X_initial' in locals() and 'Y_initial' in locals():\n",
    "    print(\"使用初始数据训练代理模型...\")\n",
    "    initial_history = adaptive_model.train(X_initial, Y_initial, epochs=150, verbose=1)\n",
    "    \n",
    "    # 评估初始模型性能\n",
    "    X_test_init, X_val_init, y_test_init, y_val_init = train_test_split(\n",
    "        X_initial, Y_initial, test_size=0.2, random_state=42\n",
    "    )\n",
    "    initial_performance = adaptive_model.evaluate_performance(X_val_init, y_val_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4b8629",
   "metadata": {},
   "source": [
    "## 第四部分：增强型DANTE优化系统\n",
    "\n",
    "创建一个能够与科学计算反馈集成的DANTE优化系统。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b7f1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterativeDANTEOptimizer:\n",
    "    \"\"\"\n",
    "    迭代DANTE优化器\n",
    "    集成科学计算反馈的闭环优化系统\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, initial_X, initial_Y, sci_computer, surrogate_model):\n",
    "        self.X_data = initial_X.copy()\n",
    "        self.Y_data = initial_Y.copy()\n",
    "        self.sci_computer = sci_computer\n",
    "        self.surrogate_model = surrogate_model\n",
    "        self.optimization_history = []\n",
    "        self.iteration_count = 0\n",
    "        \n",
    "        # 设置搜索边界\n",
    "        self.bounds_low = np.array([\n",
    "            self.X_data[:, 0].min() * 0.8,  # Co\n",
    "            self.X_data[:, 1].min() * 0.8,  # Mo  \n",
    "            self.X_data[:, 2].min() * 0.8,  # Ti\n",
    "            self.X_data[:, 3].min() * 0.8   # Fe\n",
    "        ])\n",
    "        self.bounds_high = np.array([\n",
    "            min(self.X_data[:, 0].max() * 1.2, 50),  # Co max 50%\n",
    "            min(self.X_data[:, 1].max() * 1.2, 30),  # Mo max 30%\n",
    "            min(self.X_data[:, 2].max() * 1.2, 20),  # Ti max 20%\n",
    "            self.X_data[:, 3].max() * 1.1             # Fe\n",
    "        ])\n",
    "        \n",
    "        print(f\"搜索边界设置：\")\n",
    "        print(f\"  Co: [{self.bounds_low[0]:.2f}, {self.bounds_high[0]:.2f}]%\")\n",
    "        print(f\"  Mo: [{self.bounds_low[1]:.2f}, {self.bounds_high[1]:.2f}]%\")\n",
    "        print(f\"  Ti: [{self.bounds_low[2]:.2f}, {self.bounds_high[2]:.2f}]%\")\n",
    "        print(f\"  Fe: [{self.bounds_low[3]:.2f}, {self.bounds_high[3]:.2f}]%\")\n",
    "    \n",
    "    def enforce_composition_constraint(self, compositions):\n",
    "        \"\"\"强制执行成分约束\"\"\"\n",
    "        constrained_compositions = []\n",
    "        for comp in compositions:\n",
    "            # 边界约束\n",
    "            comp_clipped = np.clip(comp, self.bounds_low, self.bounds_high)\n",
    "            \n",
    "            # 成分总和约束\n",
    "            total = np.sum(comp_clipped)\n",
    "            if not np.isclose(total, 100.0, rtol=0.01):\n",
    "                comp_clipped = comp_clipped * 100.0 / total\n",
    "            \n",
    "            # 再次边界检查\n",
    "            comp_clipped = np.clip(comp_clipped, self.bounds_low, self.bounds_high)\n",
    "            constrained_compositions.append(comp_clipped)\n",
    "        \n",
    "        return np.array(constrained_compositions)\n",
    "    \n",
    "    def optimize_with_dante(self, num_candidates=5, num_iterations=3):\n",
    "        \"\"\"使用DANTE寻找候选解\"\"\"\n",
    "        print(f\"\\n=== DANTE优化 (迭代 {self.iteration_count + 1}) ===\")\n",
    "        print(f\"当前数据集大小: {len(self.X_data)} 个样本\")\n",
    "        \n",
    "        # 创建临时目标函数\n",
    "        class TempObjectiveFunction:\n",
    "            def __init__(self, X_data, Y_data, bounds_low, bounds_high):\n",
    "                self.X_data = X_data\n",
    "                self.Y_data = Y_data\n",
    "                self.lb = bounds_low\n",
    "                self.ub = bounds_high\n",
    "            \n",
    "            def __call__(self, x):\n",
    "                distances = np.linalg.norm(self.X_data - x, axis=1)\n",
    "                nearest_idx = np.argmin(distances)\n",
    "                return -self.Y_data[nearest_idx]  # 负值转换为最小化问题\n",
    "        \n",
    "        temp_obj_func = TempObjectiveFunction(self.X_data, self.Y_data, \n",
    "                                            self.bounds_low, self.bounds_high)\n",
    "        \n",
    "        # 使用树搜索生成候选点\n",
    "        candidates = []\n",
    "        for i in range(num_iterations):\n",
    "            # 随机生成候选点\n",
    "            random_candidates = []\n",
    "            for _ in range(num_candidates):\n",
    "                candidate = np.random.uniform(self.bounds_low, self.bounds_high)\n",
    "                random_candidates.append(candidate)\n",
    "            \n",
    "            # 约束处理\n",
    "            constrained_candidates = self.enforce_composition_constraint(random_candidates)\n",
    "            \n",
    "            # 使用代理模型评估候选点\n",
    "            candidate_scores = []\n",
    "            for candidate in constrained_candidates:\n",
    "                try:\n",
    "                    pred_performance = self.surrogate_model.predict(candidate.reshape(1, -1))[0, 0]\n",
    "                    candidate_scores.append((candidate, pred_performance))\n",
    "                except:\n",
    "                    candidate_scores.append((candidate, 0.0))\n",
    "            \n",
    "            # 选择最有希望的候选点\n",
    "            candidate_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "            best_candidates = [x[0] for x in candidate_scores[:num_candidates//2]]\n",
    "            candidates.extend(best_candidates)\n",
    "        \n",
    "        # 去重并选择最终候选点\n",
    "        unique_candidates = []\n",
    "        for candidate in candidates:\n",
    "            is_duplicate = False\n",
    "            for existing in unique_candidates:\n",
    "                if np.linalg.norm(candidate - existing) < 1.0:  # 1% 差异阈值\n",
    "                    is_duplicate = True\n",
    "                    break\n",
    "            if not is_duplicate:\n",
    "                unique_candidates.append(candidate)\n",
    "        \n",
    "        # 限制候选点数量\n",
    "        final_candidates = unique_candidates[:num_candidates]\n",
    "        \n",
    "        print(f\"生成 {len(final_candidates)} 个候选解进行科学计算验证\")\n",
    "        return final_candidates\n",
    "    \n",
    "    def run_iteration(self, num_candidates=5):\n",
    "        \"\"\"运行一次完整的优化迭代\"\"\"\n",
    "        self.iteration_count += 1\n",
    "        iteration_start_time = time.time()\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"开始优化迭代 #{self.iteration_count}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # 步骤1: DANTE优化生成候选解\n",
    "        candidates = self.optimize_with_dante(num_candidates=num_candidates)\n",
    "        \n",
    "        # 步骤2: 科学计算验证\n",
    "        verified_results = []\n",
    "        successful_calculations = 0\n",
    "        \n",
    "        for i, candidate in enumerate(candidates):\n",
    "            print(f\"\\n--- 验证候选解 {i+1}/{len(candidates)} ---\")\n",
    "            elastic, yield_strength, success = self.sci_computer.compute_properties(candidate)\n",
    "            \n",
    "            if success:\n",
    "                # 计算综合性能（与初始数据处理一致）\n",
    "                elastic_norm = (elastic - elastic_min) / (elastic_max - elastic_min)\n",
    "                yield_norm = (yield_strength - yield_min) / (yield_max - yield_min)\n",
    "                performance = (elastic_norm + yield_norm) / 2\n",
    "                \n",
    "                verified_results.append({\n",
    "                    'composition': candidate,\n",
    "                    'elastic': elastic,\n",
    "                    'yield': yield_strength,\n",
    "                    'performance': performance,\n",
    "                    'predicted_performance': self.surrogate_model.predict(candidate.reshape(1, -1))[0, 0]\n",
    "                })\n",
    "                successful_calculations += 1\n",
    "        \n",
    "        # 步骤3: 更新数据集\n",
    "        if verified_results:\n",
    "            new_X = np.array([result['composition'] for result in verified_results])\n",
    "            new_Y = np.array([result['performance'] for result in verified_results])\n",
    "            \n",
    "            self.X_data = np.vstack([self.X_data, new_X])\n",
    "            self.Y_data = np.hstack([self.Y_data, new_Y])\n",
    "            \n",
    "            print(f\"\\n数据集更新: 添加 {len(verified_results)} 个新样本\")\n",
    "            print(f\"数据集总大小: {len(self.X_data)} 个样本\")\n",
    "            \n",
    "            # 步骤4: 重新训练代理模型\n",
    "            print(f\"\\n重新训练代理模型...\")\n",
    "            self.surrogate_model.train(self.X_data, self.Y_data, epochs=100, verbose=0)\n",
    "        \n",
    "        # 记录迭代历史\n",
    "        iteration_time = time.time() - iteration_start_time\n",
    "        best_idx = np.argmax(self.Y_data)\n",
    "        \n",
    "        iteration_record = {\n",
    "            'iteration': self.iteration_count,\n",
    "            'candidates_generated': len(candidates),\n",
    "            'successful_calculations': successful_calculations,\n",
    "            'new_samples_added': len(verified_results),\n",
    "            'total_samples': len(self.X_data),\n",
    "            'best_performance': self.Y_data[best_idx],\n",
    "            'best_composition': self.X_data[best_idx].copy(),\n",
    "            'iteration_time': iteration_time,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        self.optimization_history.append(iteration_record)\n",
    "        \n",
    "        print(f\"\\n=== 迭代 #{self.iteration_count} 完成 ===\")\n",
    "        print(f\"用时: {iteration_time:.2f} 秒\")\n",
    "        print(f\"成功计算: {successful_calculations}/{len(candidates)}\")\n",
    "        print(f\"当前最佳性能: {iteration_record['best_performance']:.6f}\")\n",
    "        print(f\"最佳成分: Co={iteration_record['best_composition'][0]:.2f}%, \"\n",
    "              f\"Mo={iteration_record['best_composition'][1]:.2f}%, \"\n",
    "              f\"Ti={iteration_record['best_composition'][2]:.2f}%, \"\n",
    "              f\"Fe={iteration_record['best_composition'][3]:.2f}%\")\n",
    "        \n",
    "        return iteration_record\n",
    "    \n",
    "    def get_current_best(self):\n",
    "        \"\"\"获取当前最佳结果\"\"\"\n",
    "        best_idx = np.argmax(self.Y_data)\n",
    "        return {\n",
    "            'composition': self.X_data[best_idx],\n",
    "            'performance': self.Y_data[best_idx],\n",
    "            'index': best_idx\n",
    "        }\n",
    "    \n",
    "    def plot_optimization_progress(self):\n",
    "        \"\"\"绘制优化进度\"\"\"\n",
    "        if not self.optimization_history:\n",
    "            print(\"尚未进行优化迭代\")\n",
    "            return\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        iterations = [record['iteration'] for record in self.optimization_history]\n",
    "        best_performances = [record['best_performance'] for record in self.optimization_history]\n",
    "        total_samples = [record['total_samples'] for record in self.optimization_history]\n",
    "        successful_calcs = [record['successful_calculations'] for record in self.optimization_history]\n",
    "        \n",
    "        # 最佳性能进展\n",
    "        axes[0, 0].plot(iterations, best_performances, 'o-', linewidth=2, markersize=8)\n",
    "        axes[0, 0].set_xlabel('迭代次数')\n",
    "        axes[0, 0].set_ylabel('最佳性能')\n",
    "        axes[0, 0].set_title('优化进展')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 数据集增长\n",
    "        axes[0, 1].plot(iterations, total_samples, 's-', linewidth=2, markersize=8, color='green')\n",
    "        axes[0, 1].set_xlabel('迭代次数')\n",
    "        axes[0, 1].set_ylabel('总样本数')\n",
    "        axes[0, 1].set_title('数据集增长')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 成功计算统计\n",
    "        axes[1, 0].bar(iterations, successful_calcs, alpha=0.7, color='orange')\n",
    "        axes[1, 0].set_xlabel('迭代次数')\n",
    "        axes[1, 0].set_ylabel('成功计算数')\n",
    "        axes[1, 0].set_title('科学计算成功率')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 最佳成分演化\n",
    "        colors = ['blue', 'green', 'orange', 'red']\n",
    "        elements = ['Co', 'Mo', 'Ti', 'Fe']\n",
    "        \n",
    "        for i, element in enumerate(elements):\n",
    "            compositions = [record['best_composition'][i] for record in self.optimization_history]\n",
    "            axes[1, 1].plot(iterations, compositions, 'o-', label=element, \n",
    "                          color=colors[i], linewidth=2, markersize=6)\n",
    "        \n",
    "        axes[1, 1].set_xlabel('迭代次数')\n",
    "        axes[1, 1].set_ylabel('成分 (%)')\n",
    "        axes[1, 1].set_title('最佳成分演化')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('iterative_optimization_progress.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "# 创建迭代优化器\n",
    "if all(var in locals() for var in ['X_initial', 'Y_initial', 'sci_computer', 'adaptive_model']):\n",
    "    dante_optimizer = IterativeDANTEOptimizer(\n",
    "        X_initial, Y_initial, sci_computer, adaptive_model\n",
    "    )\n",
    "    print(\"迭代DANTE优化器创建完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974b964c",
   "metadata": {},
   "source": [
    "## 第五部分：运行迭代优化\n",
    "\n",
    "现在运行完整的迭代优化过程，观察系统如何通过科学计算反馈持续改进。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "094ef223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始迭代优化过程...\n",
      "计划进行 5 轮迭代，每轮 3 个候选解\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dante_optimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m计划进行 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_iterations\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m 轮迭代，每轮 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcandidates_per_iteration\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m 个候选解\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# 记录初始状态\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m initial_best = \u001b[43mdante_optimizer\u001b[49m.get_current_best()\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m初始最佳性能: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minitial_best[\u001b[33m'\u001b[39m\u001b[33mperformance\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m初始最佳成分: Co=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minitial_best[\u001b[33m'\u001b[39m\u001b[33mcomposition\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     12\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMo=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minitial_best[\u001b[33m'\u001b[39m\u001b[33mcomposition\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     13\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTi=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minitial_best[\u001b[33m'\u001b[39m\u001b[33mcomposition\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m2\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     14\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFe=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minitial_best[\u001b[33m'\u001b[39m\u001b[33mcomposition\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m3\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'dante_optimizer' is not defined"
     ]
    }
   ],
   "source": [
    "# 运行多轮迭代优化\n",
    "num_iterations = 5  # 可以根据需要调整\n",
    "candidates_per_iteration = 3  # 每轮生成的候选数量\n",
    "\n",
    "print(\"开始迭代优化过程...\")\n",
    "print(f\"计划进行 {num_iterations} 轮迭代，每轮 {candidates_per_iteration} 个候选解\")\n",
    "\n",
    "# 记录初始状态\n",
    "initial_best = dante_optimizer.get_current_best()\n",
    "print(f\"\\n初始最佳性能: {initial_best['performance']:.6f}\")\n",
    "print(f\"初始最佳成分: Co={initial_best['composition'][0]:.2f}%, \"\n",
    "      f\"Mo={initial_best['composition'][1]:.2f}%, \"\n",
    "      f\"Ti={initial_best['composition'][2]:.2f}%, \"\n",
    "      f\"Fe={initial_best['composition'][3]:.2f}%\")\n",
    "\n",
    "# 执行迭代\n",
    "try:\n",
    "    for iteration in range(num_iterations):\n",
    "        print(f\"\\n\" + \"=\"*80)\n",
    "        print(f\"执行迭代 {iteration + 1}/{num_iterations}\")\n",
    "        print(f\"=\"*80)\n",
    "        \n",
    "        # 运行一次完整迭代\n",
    "        iteration_result = dante_optimizer.run_iteration(\n",
    "            num_candidates=candidates_per_iteration\n",
    "        )\n",
    "        \n",
    "        # 显示进展\n",
    "        if iteration > 0:\n",
    "            prev_best = dante_optimizer.optimization_history[iteration-1]['best_performance']\n",
    "            current_best = iteration_result['best_performance']\n",
    "            improvement = current_best - prev_best\n",
    "            print(f\"性能改进: {improvement:+.6f}\")\n",
    "        \n",
    "        # 中途保存（可选）\n",
    "        if (iteration + 1) % 2 == 0:\n",
    "            adaptive_model.save_model(f\"adaptive_model_iter_{iteration + 1}\")\n",
    "            print(f\"已保存中间模型\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n优化过程被用户中断\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n优化过程出现错误: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# 显示最终结果\n",
    "final_best = dante_optimizer.get_current_best()\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"迭代优化完成！\")\n",
    "print(f\"=\"*80)\n",
    "print(f\"最终最佳性能: {final_best['performance']:.6f}\")\n",
    "print(f\"最终最佳成分: Co={final_best['composition'][0]:.2f}%, \"\n",
    "      f\"Mo={final_best['composition'][1]:.2f}%, \"\n",
    "      f\"Ti={final_best['composition'][2]:.2f}%, \"\n",
    "      f\"Fe={final_best['composition'][3]:.2f}%\")\n",
    "\n",
    "if 'initial_best' in locals():\n",
    "    total_improvement = final_best['performance'] - initial_best['performance']\n",
    "    print(f\"总体改进: {total_improvement:+.6f} ({total_improvement/initial_best['performance']*100:+.2f}%)\")\n",
    "\n",
    "print(f\"\\n总计算次数: {sci_computer.calculation_count}\")\n",
    "print(f\"数据集最终大小: {len(dante_optimizer.X_data)} 个样本\")\n",
    "print(f\"模型当前版本: {adaptive_model.model_version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ff5cd4",
   "metadata": {},
   "source": [
    "## 第六部分：结果分析与可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80885bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制优化进度\n",
    "dante_optimizer.plot_optimization_progress()\n",
    "\n",
    "# 详细分析模型改进\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"模型训练历史分析\")\n",
    "print(\"=\"*60)\n",
    "print(adaptive_model.get_training_summary())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"科学计算统计\")\n",
    "print(\"=\"*60)\n",
    "print(sci_computer.get_calculation_summary())\n",
    "\n",
    "# 分析预测精度改进\n",
    "if dante_optimizer.optimization_history:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"预测精度分析\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 计算每次迭代后的预测误差\n",
    "    prediction_errors = []\n",
    "    for i, record in enumerate(dante_optimizer.optimization_history):\n",
    "        if i > 0:  # 从第二次迭代开始有新数据\n",
    "            # 使用当前迭代前的数据评估模型\n",
    "            iteration_data_size = record['total_samples'] - record['new_samples_added']\n",
    "            print(f\"迭代 {record['iteration']}: 数据量 {iteration_data_size} -> {record['total_samples']}\")\n",
    "\n",
    "# 创建综合结果可视化\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "\n",
    "# 1. 成分空间探索\n",
    "ax = axes[0, 0]\n",
    "scatter = ax.scatter(dante_optimizer.X_data[:len(X_initial), 0], \n",
    "                    dante_optimizer.X_data[:len(X_initial), 1], \n",
    "                    c=dante_optimizer.Y_data[:len(X_initial)], \n",
    "                    cmap='viridis', alpha=0.6, s=50, label='初始数据')\n",
    "\n",
    "if len(dante_optimizer.X_data) > len(X_initial):\n",
    "    ax.scatter(dante_optimizer.X_data[len(X_initial):, 0], \n",
    "              dante_optimizer.X_data[len(X_initial):, 1], \n",
    "              c=dante_optimizer.Y_data[len(X_initial):], \n",
    "              cmap='plasma', alpha=0.8, s=100, marker='^', label='新发现点')\n",
    "\n",
    "ax.scatter(final_best['composition'][0], final_best['composition'][1], \n",
    "          color='red', s=200, marker='*', label='最佳解')\n",
    "ax.set_xlabel('Co 含量 (%)')\n",
    "ax.set_ylabel('Mo 含量 (%)')\n",
    "ax.set_title('Co-Mo 成分空间探索')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Ti-Fe 成分空间\n",
    "ax = axes[0, 1]\n",
    "scatter = ax.scatter(dante_optimizer.X_data[:len(X_initial), 2], \n",
    "                    dante_optimizer.X_data[:len(X_initial), 3], \n",
    "                    c=dante_optimizer.Y_data[:len(X_initial)], \n",
    "                    cmap='viridis', alpha=0.6, s=50)\n",
    "\n",
    "if len(dante_optimizer.X_data) > len(X_initial):\n",
    "    ax.scatter(dante_optimizer.X_data[len(X_initial):, 2], \n",
    "              dante_optimizer.X_data[len(X_initial):, 3], \n",
    "              c=dante_optimizer.Y_data[len(X_initial):], \n",
    "              cmap='plasma', alpha=0.8, s=100, marker='^')\n",
    "\n",
    "ax.scatter(final_best['composition'][2], final_best['composition'][3], \n",
    "          color='red', s=200, marker='*')\n",
    "ax.set_xlabel('Ti 含量 (%)')\n",
    "ax.set_ylabel('Fe 含量 (%)')\n",
    "ax.set_title('Ti-Fe 成分空间探索')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. 性能分布对比\n",
    "ax = axes[0, 2]\n",
    "ax.hist(Y_initial, bins=20, alpha=0.6, label='初始数据', color='blue')\n",
    "if len(dante_optimizer.Y_data) > len(Y_initial):\n",
    "    ax.hist(dante_optimizer.Y_data[len(Y_initial):], bins=10, alpha=0.8, \n",
    "           label='新发现点', color='orange')\n",
    "ax.axvline(final_best['performance'], color='red', linestyle='--', \n",
    "          linewidth=2, label='最佳性能')\n",
    "ax.set_xlabel('性能值')\n",
    "ax.set_ylabel('频次')\n",
    "ax.set_title('性能分布对比')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. 模型预测 vs 真实值\n",
    "if len(dante_optimizer.X_data) > len(X_initial):\n",
    "    ax = axes[1, 0]\n",
    "    new_X = dante_optimizer.X_data[len(X_initial):]\n",
    "    new_Y_true = dante_optimizer.Y_data[len(X_initial):]\n",
    "    new_Y_pred = adaptive_model.predict(new_X).flatten()\n",
    "    \n",
    "    ax.scatter(new_Y_true, new_Y_pred, alpha=0.7, s=80)\n",
    "    min_val, max_val = min(new_Y_true.min(), new_Y_pred.min()), max(new_Y_true.max(), new_Y_pred.max())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
    "    ax.set_xlabel('真实性能')\n",
    "    ax.set_ylabel('预测性能')\n",
    "    ax.set_title('模型预测精度 (新数据)')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 计算预测精度\n",
    "    r2 = r2_score(new_Y_true, new_Y_pred)\n",
    "    ax.text(0.05, 0.95, f'R² = {r2:.3f}', transform=ax.transAxes, \n",
    "           bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# 5. 科学计算历史\n",
    "ax = axes[1, 1]\n",
    "calc_history = sci_computer.calculation_history\n",
    "if calc_history:\n",
    "    calc_performances = [record['performance'] for record in calc_history]\n",
    "    calc_numbers = list(range(1, len(calc_performances) + 1))\n",
    "    ax.plot(calc_numbers, calc_performances, 'o-', linewidth=2, markersize=6)\n",
    "    ax.set_xlabel('计算序号')\n",
    "    ax.set_ylabel('计算得到的性能')\n",
    "    ax.set_title('科学计算历史')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. 最佳成分雷达图\n",
    "ax = axes[1, 2]\n",
    "ax.remove()\n",
    "ax = fig.add_subplot(2, 3, 6, projection='polar')\n",
    "\n",
    "elements = ['Co', 'Mo', 'Ti', 'Fe']\n",
    "angles = np.linspace(0, 2 * np.pi, len(elements), endpoint=False).tolist()\n",
    "angles += angles[:1]\n",
    "\n",
    "# 初始最佳成分\n",
    "initial_comp = initial_best['composition'].tolist() + [initial_best['composition'][0]]\n",
    "final_comp = final_best['composition'].tolist() + [final_best['composition'][0]]\n",
    "\n",
    "ax.plot(angles, initial_comp, 'o-', linewidth=2, label='初始最佳', alpha=0.7)\n",
    "ax.plot(angles, final_comp, 'o-', linewidth=2, label='最终最佳', alpha=0.7)\n",
    "ax.fill(angles, final_comp, alpha=0.2)\n",
    "\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(elements)\n",
    "ax.set_title('最佳成分对比', pad=20)\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.2, 1.0))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('iterative_optimization_comprehensive_results.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f78b63c",
   "metadata": {},
   "source": [
    "## 第七部分：系统总结与分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b65129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成详细的优化报告\n",
    "print(\"=\"*80)\n",
    "print(\"DANTE 迭代优化系统 - 最终报告\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 基本统计\n",
    "print(f\"\\n【优化统计】\")\n",
    "print(f\"初始数据集大小: {len(X_initial)} 个样本\")\n",
    "print(f\"最终数据集大小: {len(dante_optimizer.X_data)} 个样本\")\n",
    "print(f\"新增样本数量: {len(dante_optimizer.X_data) - len(X_initial)}\")\n",
    "print(f\"总迭代次数: {dante_optimizer.iteration_count}\")\n",
    "print(f\"总科学计算次数: {sci_computer.calculation_count}\")\n",
    "print(f\"模型版本数: {adaptive_model.model_version}\")\n",
    "\n",
    "# 性能改进\n",
    "if 'initial_best' in locals() and 'final_best' in locals():\n",
    "    performance_improvement = final_best['performance'] - initial_best['performance']\n",
    "    relative_improvement = (performance_improvement / initial_best['performance']) * 100\n",
    "    \n",
    "    print(f\"\\n【性能改进】\")\n",
    "    print(f\"初始最佳性能: {initial_best['performance']:.6f}\")\n",
    "    print(f\"最终最佳性能: {final_best['performance']:.6f}\")\n",
    "    print(f\"绝对改进: {performance_improvement:+.6f}\")\n",
    "    print(f\"相对改进: {relative_improvement:+.2f}%\")\n",
    "\n",
    "# 成分变化分析\n",
    "if 'initial_best' in locals() and 'final_best' in locals():\n",
    "    print(f\"\\n【最佳成分变化】\")\n",
    "    elements = ['Co', 'Mo', 'Ti', 'Fe']\n",
    "    for i, element in enumerate(elements):\n",
    "        initial_val = initial_best['composition'][i]\n",
    "        final_val = final_best['composition'][i]\n",
    "        change = final_val - initial_val\n",
    "        print(f\"{element}: {initial_val:.2f}% → {final_val:.2f}% (变化: {change:+.2f}%)\")\n",
    "\n",
    "# 计算效率分析\n",
    "if dante_optimizer.optimization_history:\n",
    "    total_time = sum(record['iteration_time'] for record in dante_optimizer.optimization_history)\n",
    "    avg_time_per_iteration = total_time / len(dante_optimizer.optimization_history)\n",
    "    avg_time_per_calculation = total_time / sci_computer.calculation_count if sci_computer.calculation_count > 0 else 0\n",
    "    \n",
    "    print(f\"\\n【计算效率】\")\n",
    "    print(f\"总优化时间: {total_time:.2f} 秒\")\n",
    "    print(f\"平均每轮迭代时间: {avg_time_per_iteration:.2f} 秒\")\n",
    "    print(f\"平均每次科学计算时间: {avg_time_per_calculation:.2f} 秒\")\n",
    "\n",
    "# 模型精度分析\n",
    "if len(dante_optimizer.X_data) > len(X_initial):\n",
    "    new_data_X = dante_optimizer.X_data[len(X_initial):]\n",
    "    new_data_Y = dante_optimizer.Y_data[len(X_initial):]\n",
    "    \n",
    "    if len(new_data_X) > 0:\n",
    "        predictions = adaptive_model.predict(new_data_X).flatten()\n",
    "        mse = mean_squared_error(new_data_Y, predictions)\n",
    "        r2 = r2_score(new_data_Y, predictions)\n",
    "        \n",
    "        print(f\"\\n【模型精度 (新数据)】\")\n",
    "        print(f\"均方误差 (MSE): {mse:.6f}\")\n",
    "        print(f\"决定系数 (R²): {r2:.3f}\")\n",
    "        print(f\"预测样本数: {len(new_data_X)}\")\n",
    "\n",
    "# 科学计算成功率\n",
    "if sci_computer.calculation_history:\n",
    "    total_attempts = len(dante_optimizer.optimization_history) * candidates_per_iteration if 'candidates_per_iteration' in locals() else sci_computer.calculation_count\n",
    "    success_rate = (sci_computer.calculation_count / total_attempts) * 100 if total_attempts > 0 else 0\n",
    "    \n",
    "    print(f\"\\n【科学计算统计】\")\n",
    "    print(f\"计算成功率: {success_rate:.1f}%\")\n",
    "    print(f\"平均计算时间: {np.mean([r['computation_time'] for r in sci_computer.calculation_history]):.2f} 秒\")\n",
    "\n",
    "# 保存最终结果\n",
    "final_results = {\n",
    "    'optimization_summary': {\n",
    "        'initial_dataset_size': len(X_initial),\n",
    "        'final_dataset_size': len(dante_optimizer.X_data),\n",
    "        'total_iterations': dante_optimizer.iteration_count,\n",
    "        'total_calculations': sci_computer.calculation_count,\n",
    "        'model_versions': adaptive_model.model_version\n",
    "    },\n",
    "    'performance_results': {\n",
    "        'initial_best_performance': initial_best['performance'] if 'initial_best' in locals() else None,\n",
    "        'final_best_performance': final_best['performance'],\n",
    "        'improvement': performance_improvement if 'performance_improvement' in locals() else None,\n",
    "        'relative_improvement_percent': relative_improvement if 'relative_improvement' in locals() else None\n",
    "    },\n",
    "    'best_composition': {\n",
    "        'Co': final_best['composition'][0],\n",
    "        'Mo': final_best['composition'][1], \n",
    "        'Ti': final_best['composition'][2],\n",
    "        'Fe': final_best['composition'][3]\n",
    "    },\n",
    "    'optimization_history': dante_optimizer.optimization_history,\n",
    "    'timestamp': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "# 保存结果到文件\n",
    "with open('iterative_optimization_results.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(final_results, f, indent=2, ensure_ascii=False, default=str)\n",
    "\n",
    "print(f\"\\n【保存结果】\")\n",
    "print(f\"详细结果已保存到: iterative_optimization_results.json\")\n",
    "print(f\"图表已保存到: iterative_optimization_comprehensive_results.png\")\n",
    "print(f\"优化进度图已保存到: iterative_optimization_progress.png\")\n",
    "\n",
    "# 保存最终模型\n",
    "adaptive_model.save_model(\"final_adaptive_model\")\n",
    "print(f\"最终模型已保存: final_adaptive_model_v{adaptive_model.model_version}.keras\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"迭代优化系统运行完成！\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540bab76",
   "metadata": {},
   "source": [
    "## 总结与展望\n",
    "\n",
    "### 🎯 系统特点\n",
    "\n",
    "本notebook实现了一个完整的**科学计算反馈闭环优化系统**，具有以下特点：\n",
    "\n",
    "1. **智能候选生成**: DANTE算法基于代理模型智能生成最有希望的候选解\n",
    "2. **科学计算验证**: 通过模拟的科学计算软件验证候选解的真实性能\n",
    "3. **增量学习**: 代理模型能够持续学习新的实验数据，不断提升预测精度\n",
    "4. **约束处理**: 自动处理材料科学的物理约束（成分总和100%等）\n",
    "5. **进度追踪**: 完整记录优化过程，便于分析和调试\n",
    "\n",
    "### 🔬 实际应用\n",
    "\n",
    "在真实的材料设计场景中，本系统可以：\n",
    "\n",
    "- 将**VASP/Quantum ESPRESSO**等DFT软件作为科学计算引擎\n",
    "- 连接**LAMMPS/GROMACS**等分子动力学模拟软件\n",
    "- 集成**实验设备**进行真实材料合成和测试\n",
    "- 对接**高通量计算平台**进行大规模并行优化\n",
    "\n",
    "### 🚀 优势分析\n",
    "\n",
    "相比传统优化方法，该系统具有：\n",
    "\n",
    "1. **效率提升**: 代理模型大幅减少昂贵的科学计算需求\n",
    "2. **精度改进**: 持续学习机制确保模型精度不断提升\n",
    "3. **智能探索**: 平衡exploitation和exploration，避免局部最优\n",
    "4. **可解释性**: 提供完整的优化路径和决策依据\n",
    "\n",
    "### 📈 扩展方向\n",
    "\n",
    "未来可以进一步扩展：\n",
    "\n",
    "1. **多目标优化**: 同时优化多个性能指标（强度、韧性、耐腐蚀性等）\n",
    "2. **不确定性量化**: 引入贝叶斯方法处理实验噪声和模型不确定性\n",
    "3. **主动学习策略**: 更智能的样本选择策略（期望改进、置信区间等）\n",
    "4. **分布式计算**: 支持多节点并行计算和优化\n",
    "5. **实时监控**: Web界面实时监控优化进展\n",
    "\n",
    "这个系统展示了**人工智能**与**材料科学**深度融合的巨大潜力，为加速新材料发现提供了强大的工具！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ljk2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
