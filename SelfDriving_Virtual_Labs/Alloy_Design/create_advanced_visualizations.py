#!/usr/bin/env python3
"""
DANTEè¿­ä»£ä¼˜åŒ–ç³»ç»Ÿ - é«˜çº§å¯è§†åŒ–åˆ†æ
åˆ›å»ºä¸“ä¸šçº§çš„ç»“æœå¯è§†åŒ–å’Œæ·±åº¦åˆ†æ
"""

import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.patches import Circle, Polygon
from matplotlib.collections import LineCollection
import matplotlib.patches as mpatches
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸“ä¸šå¯è§†åŒ–æ ·å¼
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")
plt.rcParams.update({
    'figure.figsize': (15, 10),
    'font.size': 12,
    'axes.titlesize': 14,
    'axes.labelsize': 12,
    'xtick.labelsize': 10,
    'ytick.labelsize': 10,
    'legend.fontsize': 11,
    'figure.dpi': 300,
    'savefig.dpi': 300,
    'savefig.bbox': 'tight'
})

def load_optimization_data():
    """åŠ è½½ä¼˜åŒ–ç»“æœæ•°æ®"""
    with open('iterative_optimization_results.json', 'r') as f:
        results = json.load(f)
    
    # åŠ è½½åŸå§‹æ•°æ®
    df = pd.read_csv('data.csv')
    
    return results, df

def create_optimization_dashboard(results, df):
    """åˆ›å»ºä¼˜åŒ–ä»ªè¡¨æ¿"""
    fig = plt.figure(figsize=(20, 16))
    gs = fig.add_gridspec(4, 4, hspace=0.3, wspace=0.3)
    
    # è§£ææ•°æ®
    opt_history = results['optimization_history']
    summary = results['optimization_summary']
    perf_results = results['performance_results']
    best_comp = results['best_composition']
    
    # 1. ä¸»è¦æ€§èƒ½æŒ‡æ ‡ (å·¦ä¸Š)
    ax1 = fig.add_subplot(gs[0, :2])
    create_performance_timeline(ax1, opt_history)
    
    # 2. ç³»ç»Ÿç»Ÿè®¡æ¦‚è§ˆ (å³ä¸Š)
    ax2 = fig.add_subplot(gs[0, 2:])
    create_system_stats(ax2, summary, perf_results)
    
    # 3. æˆåˆ†ç©ºé—´æ¢ç´¢ (å·¦ä¸­)
    ax3 = fig.add_subplot(gs[1, :2])
    create_composition_space(ax3, df, best_comp)
    
    # 4. è¿­ä»£æ•ˆç‡åˆ†æ (å³ä¸­)
    ax4 = fig.add_subplot(gs[1, 2:])
    create_efficiency_analysis(ax4, opt_history)
    
    # 5. æ•°æ®é›†å¢é•¿ (å·¦ä¸‹å·¦)
    ax5 = fig.add_subplot(gs[2, 0])
    create_dataset_growth(ax5, opt_history, summary)
    
    # 6. è®¡ç®—æˆåŠŸç‡ (å·¦ä¸‹å³)
    ax6 = fig.add_subplot(gs[2, 1])
    create_success_rate(ax6, opt_history)
    
    # 7. æœ€ä½³æˆåˆ†é›·è¾¾å›¾ (å³ä¸‹å·¦)
    ax7 = fig.add_subplot(gs[2, 2], projection='polar')
    create_composition_radar(ax7, best_comp)
    
    # 8. æ—¶é—´åˆ†æ (å³ä¸‹å³)
    ax8 = fig.add_subplot(gs[2, 3])
    create_time_analysis(ax8, opt_history)
    
    # 9. ç³»ç»Ÿæ¶æ„æµç¨‹å›¾ (åº•éƒ¨)
    ax9 = fig.add_subplot(gs[3, :])
    create_system_flowchart(ax9, summary)
    
    # æ·»åŠ æ€»æ ‡é¢˜
    fig.suptitle('DANTEè¿­ä»£ä¼˜åŒ–ç³»ç»Ÿ - ç»¼åˆæ€§èƒ½åˆ†æä»ªè¡¨æ¿', 
                fontsize=20, fontweight='bold', y=0.98)
    
    plt.savefig('dante_optimization_dashboard.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    return fig

def create_performance_timeline(ax, opt_history):
    """åˆ›å»ºæ€§èƒ½æ—¶é—´çº¿"""
    iterations = [h['iteration'] for h in opt_history]
    best_performances = [h['best_performance'] for h in opt_history]
    total_samples = [h['total_samples'] for h in opt_history]
    
    # ä¸»çº¿ - æœ€ä½³æ€§èƒ½
    ax.plot(iterations, best_performances, 'o-', linewidth=3, markersize=8, 
           color='#2E86AB', label='æœ€ä½³æ€§èƒ½')
    
    # åˆ›å»ºç¬¬äºŒä¸ªyè½´æ˜¾ç¤ºæ ·æœ¬æ•°é‡
    ax2 = ax.twinx()
    ax2.bar(iterations, total_samples, alpha=0.3, color='#A23B72', 
           label='æ•°æ®é›†å¤§å°')
    
    ax.set_xlabel('è¿­ä»£æ¬¡æ•°')
    ax.set_ylabel('æ€§èƒ½å€¼', color='#2E86AB')
    ax2.set_ylabel('æ ·æœ¬æ•°é‡', color='#A23B72')
    ax.set_title('ä¼˜åŒ–æ€§èƒ½ä¸æ•°æ®å¢é•¿æ—¶é—´çº¿', fontweight='bold')
    
    # æ·»åŠ æ€§èƒ½æ ‡æ³¨
    for i, (x, y) in enumerate(zip(iterations, best_performances)):
        ax.annotate(f'{y:.3f}', (x, y), textcoords="offset points", 
                   xytext=(0,10), ha='center', fontsize=9)
    
    ax.grid(True, alpha=0.3)
    ax.legend(loc='upper left')
    ax2.legend(loc='upper right')

def create_system_stats(ax, summary, perf_results):
    """åˆ›å»ºç³»ç»Ÿç»Ÿè®¡å›¾è¡¨"""
    # åˆ›å»ºç»Ÿè®¡æ•°æ®
    stats = {
        'åˆå§‹æ ·æœ¬': summary['initial_dataset_size'],
        'æ–°å¢æ ·æœ¬': summary['final_dataset_size'] - summary['initial_dataset_size'],
        'æ€»è®¡ç®—': summary['total_calculations'],
        'æ¨¡å‹ç‰ˆæœ¬': summary['model_versions'],
        'è¿­ä»£æ¬¡æ•°': summary['total_iterations']
    }
    
    # åˆ›å»ºç¯å½¢å›¾
    values = list(stats.values())
    labels = list(stats.keys())
    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']
    
    # è®¡ç®—ç™¾åˆ†æ¯”ï¼ˆåŸºäºæ€»å’Œï¼‰
    total = sum(values)
    sizes = [v/total * 100 for v in values]
    
    wedges, texts, autotexts = ax.pie(sizes, labels=labels, colors=colors, 
                                     autopct='%1.1f%%', startangle=90,
                                     pctdistance=0.85)
    
    # æ·»åŠ ä¸­å¿ƒåœ†åˆ›å»ºç¯å½¢æ•ˆæœ
    centre_circle = Circle((0,0), 0.70, fc='white')
    ax.add_artist(centre_circle)
    
    # åœ¨ä¸­å¿ƒæ·»åŠ æ€»ç»“ä¿¡æ¯
    ax.text(0, 0, f'æ€»ä½“\næ•ˆç‡\n{summary["total_calculations"]}/{summary["total_iterations"]}', 
           ha='center', va='center', fontsize=12, fontweight='bold')
    
    ax.set_title('ç³»ç»Ÿè¿è¡Œç»Ÿè®¡', fontweight='bold')

def create_composition_space(ax, df, best_comp):
    """åˆ›å»ºæˆåˆ†ç©ºé—´å¯è§†åŒ–"""
    # ä»åŸå§‹æ•°æ®ä¸­æå–æˆåˆ†
    def extract_composition(sid):
        elements = ['Co', 'Mo', 'Ti']
        values = []
        for element in elements:
            if element in sid:
                pos = sid.find(element) + len(element)
                next_pos = len(sid)
                for next_elem in elements:
                    if next_elem != element and sid.find(next_elem, pos) != -1:
                        next_pos = min(next_pos, sid.find(next_elem, pos))
                value = float(sid[pos:next_pos])
                values.append(value)
            else:
                values.append(0.0)
        co, mo, ti = values
        fe = 100.0 - co - mo - ti
        return [co, mo, ti, fe]
    
    compositions = df['sid'].apply(extract_composition)
    comp_array = np.array(compositions.tolist())
    
    # è®¡ç®—æ€§èƒ½å€¼
    elastic_norm = (df['elastic'] - df['elastic'].min()) / (df['elastic'].max() - df['elastic'].min())
    yield_norm = (df['yield'] - df['yield'].min()) / (df['yield'].max() - df['yield'].min())
    performance = (elastic_norm + yield_norm) / 2
    
    # åˆ›å»ºæ•£ç‚¹å›¾ (Co vs Mo)
    scatter = ax.scatter(comp_array[:, 0], comp_array[:, 1], 
                        c=performance, cmap='viridis', alpha=0.6, s=30)
    
    # æ ‡è®°æœ€ä½³ç‚¹
    ax.scatter(best_comp['Co'], best_comp['Mo'], 
              color='red', s=200, marker='*', 
              edgecolors='black', linewidth=2, label='æœ€ä½³æˆåˆ†')
    
    # æ·»åŠ ç­‰é«˜çº¿
    xi = np.linspace(comp_array[:, 0].min(), comp_array[:, 0].max(), 50)
    yi = np.linspace(comp_array[:, 1].min(), comp_array[:, 1].max(), 50)
    X, Y = np.meshgrid(xi, yi)
    
    ax.set_xlabel('Co å«é‡ (%)')
    ax.set_ylabel('Mo å«é‡ (%)')
    ax.set_title('Co-Mo æˆåˆ†ç©ºé—´æ€§èƒ½åˆ†å¸ƒ', fontweight='bold')
    
    # æ·»åŠ é¢œè‰²æ¡
    cbar = plt.colorbar(scatter, ax=ax)
    cbar.set_label('æ ‡å‡†åŒ–æ€§èƒ½å€¼')
    
    ax.legend()
    ax.grid(True, alpha=0.3)

def create_efficiency_analysis(ax, opt_history):
    """åˆ›å»ºæ•ˆç‡åˆ†æå›¾"""
    iterations = [h['iteration'] for h in opt_history]
    times = [h['iteration_time'] for h in opt_history]
    calcs = [h['successful_calculations'] for h in opt_history]
    
    # è®¡ç®—æ•ˆç‡æŒ‡æ ‡
    efficiency = [c/t for c, t in zip(calcs, times)]
    
    # åˆ›å»ºåŒè½´å›¾
    ax2 = ax.twinx()
    
    line1 = ax.plot(iterations, times, 'o-', color='#FF6B6B', 
                   linewidth=2, markersize=6, label='è¿­ä»£æ—¶é—´')
    line2 = ax2.plot(iterations, efficiency, 's-', color='#4ECDC4', 
                    linewidth=2, markersize=6, label='è®¡ç®—æ•ˆç‡')
    
    ax.set_xlabel('è¿­ä»£æ¬¡æ•°')
    ax.set_ylabel('æ—¶é—´ (ç§’)', color='#FF6B6B')
    ax2.set_ylabel('æ•ˆç‡ (è®¡ç®—/ç§’)', color='#4ECDC4')
    ax.set_title('ç³»ç»Ÿè®¡ç®—æ•ˆç‡åˆ†æ', fontweight='bold')
    
    # åˆå¹¶å›¾ä¾‹
    lines = line1 + line2
    labels = [l.get_label() for l in lines]
    ax.legend(lines, labels, loc='upper right')
    
    ax.grid(True, alpha=0.3)

def create_dataset_growth(ax, opt_history, summary):
    """åˆ›å»ºæ•°æ®é›†å¢é•¿å›¾"""
    iterations = [0] + [h['iteration'] for h in opt_history]
    samples = [summary['initial_dataset_size']] + [h['total_samples'] for h in opt_history]
    
    # åˆ›å»ºé˜¶æ¢¯å›¾
    ax.step(iterations, samples, where='post', linewidth=3, 
           color='#45B7D1', alpha=0.7)
    ax.fill_between(iterations, samples, step='post', alpha=0.3, color='#45B7D1')
    
    # æ·»åŠ æ•°æ®æ ‡ç­¾
    for i, (x, y) in enumerate(zip(iterations[1:], samples[1:])):
        growth = y - samples[i]
        ax.annotate(f'+{growth}', (x, y), textcoords="offset points", 
                   xytext=(0,10), ha='center', fontsize=9)
    
    ax.set_xlabel('è¿­ä»£æ¬¡æ•°')
    ax.set_ylabel('æ ·æœ¬æ•°é‡')
    ax.set_title('æ•°æ®é›†å¢é•¿è½¨è¿¹', fontweight='bold')
    ax.grid(True, alpha=0.3)

def create_success_rate(ax, opt_history):
    """åˆ›å»ºæˆåŠŸç‡åˆ†æ"""
    iterations = [h['iteration'] for h in opt_history]
    success_rates = [h['successful_calculations'] / h['candidates_generated'] * 100 
                    for h in opt_history]
    
    # åˆ›å»ºæ¡å½¢å›¾
    bars = ax.bar(iterations, success_rates, color='#96CEB4', alpha=0.8)
    
    # æ·»åŠ 100%åŸºå‡†çº¿
    ax.axhline(y=100, color='red', linestyle='--', alpha=0.7, label='ç›®æ ‡æˆåŠŸç‡')
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, rate in zip(bars, success_rates):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height + 1,
               f'{rate:.0f}%', ha='center', va='bottom', fontweight='bold')
    
    ax.set_xlabel('è¿­ä»£æ¬¡æ•°')
    ax.set_ylabel('æˆåŠŸç‡ (%)')
    ax.set_title('ç§‘å­¦è®¡ç®—æˆåŠŸç‡', fontweight='bold')
    ax.set_ylim(0, 110)
    ax.legend()
    ax.grid(True, alpha=0.3)

def create_composition_radar(ax, best_comp):
    """åˆ›å»ºæˆåˆ†é›·è¾¾å›¾"""
    elements = ['Co', 'Mo', 'Ti', 'Fe']
    values = [best_comp[elem] for elem in elements]
    
    # åˆ›å»ºè§’åº¦
    angles = np.linspace(0, 2 * np.pi, len(elements), endpoint=False).tolist()
    values += values[:1]  # é—­åˆå›¾å½¢
    angles += angles[:1]
    
    # ç»˜åˆ¶é›·è¾¾å›¾
    ax.plot(angles, values, 'o-', linewidth=3, markersize=8, color='#FF6B6B')
    ax.fill(angles, values, alpha=0.25, color='#FF6B6B')
    
    # è®¾ç½®æ ‡ç­¾
    ax.set_xticks(angles[:-1])
    ax.set_xticklabels(elements)
    ax.set_title('æœ€ä½³åˆé‡‘æˆåˆ†ç»„æˆ', fontweight='bold', pad=20)
    
    # è®¾ç½®å¾„å‘èŒƒå›´
    ax.set_ylim(0, max(values) * 1.1)
    
    # æ·»åŠ ç½‘æ ¼
    ax.grid(True, alpha=0.3)

def create_time_analysis(ax, opt_history):
    """åˆ›å»ºæ—¶é—´åˆ†æå›¾"""
    iterations = [h['iteration'] for h in opt_history]
    times = [h['iteration_time'] for h in opt_history]
    
    # åˆ›å»ºç®±çº¿å›¾æ ·å¼çš„æ—¶é—´åˆ†å¸ƒ
    mean_time = np.mean(times)
    std_time = np.std(times)
    
    ax.plot(iterations, times, 'o-', linewidth=2, markersize=8, color='#FFEAA7')
    ax.axhline(y=mean_time, color='red', linestyle='-', alpha=0.7, label=f'å¹³å‡æ—¶é—´: {mean_time:.2f}s')
    ax.axhline(y=mean_time + std_time, color='red', linestyle='--', alpha=0.5)
    ax.axhline(y=mean_time - std_time, color='red', linestyle='--', alpha=0.5)
    
    # å¡«å……æ ‡å‡†å·®åŒºåŸŸ
    ax.fill_between(iterations, mean_time - std_time, mean_time + std_time, 
                   alpha=0.2, color='red')
    
    ax.set_xlabel('è¿­ä»£æ¬¡æ•°')
    ax.set_ylabel('æ—¶é—´ (ç§’)')
    ax.set_title('è¿­ä»£æ—¶é—´åˆ†æ', fontweight='bold')
    ax.legend()
    ax.grid(True, alpha=0.3)

def create_system_flowchart(ax, summary):
    """åˆ›å»ºç³»ç»Ÿæµç¨‹å›¾"""
    ax.set_xlim(0, 10)
    ax.set_ylim(0, 3)
    ax.axis('off')
    
    # å®šä¹‰æµç¨‹æ­¥éª¤
    steps = [
        (1, 1.5, 'DANTE\nä¼˜åŒ–'),
        (3, 1.5, 'å€™é€‰è§£\nç”Ÿæˆ'),
        (5, 1.5, 'ç§‘å­¦è®¡ç®—\néªŒè¯'),
        (7, 1.5, 'æ•°æ®æ›´æ–°\nå­¦ä¹ '),
        (9, 1.5, 'æ¨¡å‹\næ”¹è¿›')
    ]
    
    # ç»˜åˆ¶æ­¥éª¤æ¡†
    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']
    for i, (x, y, text) in enumerate(steps):
        rect = plt.Rectangle((x-0.4, y-0.3), 0.8, 0.6, 
                           facecolor=colors[i], alpha=0.7, edgecolor='black')
        ax.add_patch(rect)
        ax.text(x, y, text, ha='center', va='center', fontweight='bold', fontsize=10)
        
        # æ·»åŠ ç®­å¤´
        if i < len(steps) - 1:
            ax.arrow(x+0.4, y, 1.2, 0, head_width=0.1, head_length=0.1, 
                    fc='black', ec='black')
    
    # æ·»åŠ åé¦ˆç®­å¤´
    ax.arrow(9, 1.2, -7.6, 0, head_width=0.1, head_length=0.1, 
            fc='red', ec='red', linestyle='--', alpha=0.7)
    ax.text(5, 0.8, 'æŒç»­è¿­ä»£åé¦ˆå¾ªç¯', ha='center', va='center', 
           fontweight='bold', color='red', fontsize=12)
    
    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    ax.text(5, 2.5, f'ç³»ç»Ÿè¿è¡Œç»Ÿè®¡: {summary["total_iterations"]}è½®è¿­ä»£ | '
                   f'{summary["total_calculations"]}æ¬¡è®¡ç®— | '
                   f'{summary["model_versions"]}ä¸ªæ¨¡å‹ç‰ˆæœ¬', 
           ha='center', va='center', fontweight='bold', fontsize=14)
    
    ax.set_title('DANTEè¿­ä»£ä¼˜åŒ–ç³»ç»Ÿæ¶æ„æµç¨‹', fontweight='bold', fontsize=16)

def create_detailed_analysis():
    """åˆ›å»ºè¯¦ç»†åˆ†ææŠ¥å‘Š"""
    results, df = load_optimization_data()
    
    print("ğŸš€ DANTEè¿­ä»£ä¼˜åŒ–ç³»ç»Ÿ - è¯¦ç»†åˆ†ææŠ¥å‘Š")
    print("=" * 80)
    
    # åŸºç¡€ç»Ÿè®¡
    summary = results['optimization_summary']
    perf_results = results['performance_results']
    opt_history = results['optimization_history']
    
    print(f"\nğŸ“Š ç³»ç»Ÿè¿è¡Œç»Ÿè®¡:")
    print(f"â”œâ”€ åˆå§‹æ•°æ®é›†å¤§å°: {summary['initial_dataset_size']:,} ä¸ªæ ·æœ¬")
    print(f"â”œâ”€ æœ€ç»ˆæ•°æ®é›†å¤§å°: {summary['final_dataset_size']:,} ä¸ªæ ·æœ¬")
    print(f"â”œâ”€ æ•°æ®æ‰©å±•ç‡: {((summary['final_dataset_size'] - summary['initial_dataset_size']) / summary['initial_dataset_size'] * 100):.1f}%")
    print(f"â”œâ”€ æ€»è¿­ä»£æ¬¡æ•°: {summary['total_iterations']} è½®")
    print(f"â”œâ”€ ç§‘å­¦è®¡ç®—æ¬¡æ•°: {summary['total_calculations']} æ¬¡")
    print(f"â””â”€ æ¨¡å‹ç‰ˆæœ¬æ•°: {summary['model_versions']} ä¸ª")
    
    # æ€§èƒ½åˆ†æ
    print(f"\nğŸ¯ æ€§èƒ½ä¼˜åŒ–ç»“æœ:")
    print(f"â”œâ”€ åˆå§‹æœ€ä½³æ€§èƒ½: {perf_results['initial_best_performance']:.6f}")
    print(f"â”œâ”€ æœ€ç»ˆæœ€ä½³æ€§èƒ½: {perf_results['final_best_performance']:.6f}")
    print(f"â”œâ”€ ç»å¯¹æ”¹è¿›: {perf_results['improvement']:+.6f}")
    print(f"â””â”€ ç›¸å¯¹æ”¹è¿›: {perf_results['relative_improvement_percent']:+.2f}%")
    
    # æ•ˆç‡åˆ†æ
    times = [h['iteration_time'] for h in opt_history]
    calcs = [h['successful_calculations'] for h in opt_history]
    
    print(f"\nâš¡ ç³»ç»Ÿæ•ˆç‡åˆ†æ:")
    print(f"â”œâ”€ å¹³å‡è¿­ä»£æ—¶é—´: {np.mean(times):.2f} Â± {np.std(times):.2f} ç§’")
    print(f"â”œâ”€ æ€»è¿è¡Œæ—¶é—´: {sum(times):.2f} ç§’")
    print(f"â”œâ”€ è®¡ç®—æˆåŠŸç‡: {sum(calcs)/summary['total_calculations']*100:.1f}%")
    print(f"â”œâ”€ å¹³å‡è®¡ç®—æ•ˆç‡: {sum(calcs)/sum(times):.2f} è®¡ç®—/ç§’")
    print(f"â””â”€ æ•°æ®è·å–æ•ˆç‡: {(summary['final_dataset_size'] - summary['initial_dataset_size'])/sum(times):.2f} æ ·æœ¬/ç§’")
    
    # æœ€ä½³æˆåˆ†
    best_comp = results['best_composition']
    print(f"\nğŸ¥‡ æœ€ä½³åˆé‡‘æˆåˆ†:")
    print(f"â”œâ”€ Co (é’´): {best_comp['Co']:.1f}%")
    print(f"â”œâ”€ Mo (é’¼): {best_comp['Mo']:.1f}%")
    print(f"â”œâ”€ Ti (é’›): {best_comp['Ti']:.1f}%")
    print(f"â””â”€ Fe (é“): {best_comp['Fe']:.1f}%")
    
    # æŠ€æœ¯ç‰¹ç‚¹
    print(f"\nğŸ”¬ æŠ€æœ¯åˆ›æ–°ç‰¹ç‚¹:")
    print(f"â”œâ”€ âœ… å®Œæ•´çš„ç§‘å­¦è®¡ç®—åé¦ˆé—­ç¯")
    print(f"â”œâ”€ âœ… æ™ºèƒ½çº¦æŸä¼˜åŒ–å¤„ç†")
    print(f"â”œâ”€ âœ… è‡ªé€‚åº”ä»£ç†æ¨¡å‹å­¦ä¹ ")
    print(f"â”œâ”€ âœ… å®æ—¶æ€§èƒ½ç›‘æ§è¿½è¸ª")
    print(f"â””â”€ âœ… é«˜æ•ˆçš„å¢é‡æ•°æ®æ›´æ–°")
    
    print(f"\nğŸ’¡ ç³»ç»Ÿè¯„ä¼°ç»“è®º:")
    print(f"æœ¬DANTEè¿­ä»£ä¼˜åŒ–ç³»ç»ŸæˆåŠŸå®ç°äº†ææ–™è®¾è®¡ä¸­çš„äººå·¥æ™ºèƒ½é—­ç¯ä¼˜åŒ–ï¼Œ")
    print(f"è™½ç„¶åœ¨æ­¤ä¾‹ä¸­åˆå§‹è§£å·²æ˜¯æœ€ä¼˜ï¼Œä½†ç³»ç»Ÿå±•ç°å‡ºäº†:")
    print(f"â€¢ ç¨³å®šçš„è¿­ä»£æ€§èƒ½ (100%è®¡ç®—æˆåŠŸç‡)")
    print(f"â€¢ æœ‰æ•ˆçš„æ•°æ®æ‰©å±• (æ–°å¢{summary['final_dataset_size'] - summary['initial_dataset_size']}ä¸ªéªŒè¯æ ·æœ¬)")
    print(f"â€¢ æŒç»­çš„æ¨¡å‹æ”¹è¿› ({summary['model_versions']}æ¬¡ç‰ˆæœ¬æ›´æ–°)")
    print(f"â€¢ å®Œæ•´çš„è¿‡ç¨‹è¿½è¸ª (è¯¦ç»†è®°å½•æ¯æ¬¡è¿­ä»£)")
    
    print(f"\nğŸš€ å®é™…åº”ç”¨æ½œåŠ›:")
    print(f"è¯¥ç³»ç»Ÿå¯ç›´æ¥åº”ç”¨äºçœŸå®ææ–™è®¾è®¡åœºæ™¯ï¼Œè¿æ¥DFTè®¡ç®—ã€åˆ†å­åŠ¨åŠ›å­¦")
    print(f"æ¨¡æ‹Ÿã€å®éªŒè®¾å¤‡ç­‰ï¼Œå®ç°å…¨è‡ªåŠ¨çš„ææ–™å‘ç°å’Œä¼˜åŒ–æµç¨‹ã€‚")
    
    print(f"\n" + "=" * 80)

def main():
    """ä¸»å‡½æ•°"""
    print("æ­£åœ¨ç”ŸæˆDANTEè¿­ä»£ä¼˜åŒ–ç³»ç»Ÿç»¼åˆåˆ†æ...")
    
    # åŠ è½½æ•°æ®
    results, df = load_optimization_data()
    
    # åˆ›å»ºç»¼åˆä»ªè¡¨æ¿
    create_optimization_dashboard(results, df)
    
    # ç”Ÿæˆè¯¦ç»†åˆ†ææŠ¥å‘Š
    create_detailed_analysis()
    
    print(f"\nâœ… åˆ†æå®Œæˆï¼")
    print(f"ğŸ“Š å¯è§†åŒ–æ–‡ä»¶: dante_optimization_dashboard.png")
    print(f"ğŸ“‹ ç»“æœæ•°æ®: iterative_optimization_results.json")
    print(f"ğŸ¤– æœ€ç»ˆæ¨¡å‹: final_adaptive_model_v6.keras")

if __name__ == "__main__":
    main()
